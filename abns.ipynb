{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BxlW9QixK0J6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abf28d6b-c9b9-4b9e-b451-baa8f4c0fca9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "p7zip-full is already the newest version (16.02+dfsg-8).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 19 not upgraded.\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.11/dist-packages (5.3.2)\n",
            "Collecting nilearn\n",
            "  Downloading nilearn-0.11.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting dicom2nifti\n",
            "  Downloading dicom2nifti-2.5.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.11/dist-packages (from nibabel) (6.5.2)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from nibabel) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.11/dist-packages (from nibabel) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.11/dist-packages (from nibabel) (4.12.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from nilearn) (1.4.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from nilearn) (5.3.0)\n",
            "Requirement already satisfied: pandas>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from nilearn) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.25.0 in /usr/local/lib/python3.11/dist-packages (from nilearn) (2.32.3)\n",
            "Requirement already satisfied: scikit-learn>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from nilearn) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from nilearn) (1.13.1)\n",
            "Collecting pydicom>=2.2.0 (from dicom2nifti)\n",
            "  Downloading pydicom-3.0.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting python-gdcm (from dicom2nifti)\n",
            "  Downloading python_gdcm-3.0.24.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.0->nilearn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.0->nilearn) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.0->nilearn) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.25.0->nilearn) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.25.0->nilearn) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.25.0->nilearn) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.25.0->nilearn) (2025.1.31)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.0->nilearn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.2.0->nilearn) (1.17.0)\n",
            "Downloading nilearn-0.11.1-py3-none-any.whl (10.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dicom2nifti-2.5.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydicom-3.0.1-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_gdcm-3.0.24.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-gdcm, pydicom, dicom2nifti, nilearn\n",
            "Successfully installed dicom2nifti-2.5.1 nilearn-0.11.1 pydicom-3.0.1 python-gdcm-3.0.24.1\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.1)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.13.1)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (3.4.2)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (11.1.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.1.10)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "# Install p7zip-full for handling .7z archives\n",
        "!apt-get install -y p7zip-full\n",
        "!pip install nibabel nilearn dicom2nifti\n",
        "from scipy.ndimage import shift\n",
        "\n",
        "from nilearn.image import clean_img, resample_to_img\n",
        "import nibabel as nib\n",
        "import os\n",
        "import dicom2nifti\n",
        "import nibabel as nib\n",
        "from nilearn.image import clean_img, resample_to_img, smooth_img, resample_img\n",
        "from nilearn.masking import compute_brain_mask\n",
        "from nilearn.datasets import load_mni152_template\n",
        "import numpy as np\n",
        "from nilearn.decomposition import CanICA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from nilearn.connectome import ConnectivityMeasure\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Ridge\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "!pip install scikit-image\n",
        "from skimage.registration import phase_cross_correlation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define paths\n",
        "uploaded_file_path = '/content/drive/MyDrive/schizconnect_COBRE_images_22498.7z.001'\n",
        "output_dir = '/content/extracted_data'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "print(\"Google Drive mounted and paths defined.\")\n"
      ],
      "metadata": {
        "id": "xZl6tJVrYz17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8ba3b76-c662-4e9c-ba11-91fcebf59f1e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Google Drive mounted and paths defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename the file to .7z\n",
        "renamed_file_path = uploaded_file_path.replace('.7z.001', '.7z')\n",
        "os.rename(uploaded_file_path, renamed_file_path)\n",
        "\n",
        "print(f\"File renamed to: {renamed_file_path}\")\n"
      ],
      "metadata": {
        "id": "hjqZoRO7YuRD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "be036176-5025-45b2-9f2f-cb1fac4f003d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/schizconnect_COBRE_images_22498.7z.001' -> '/content/drive/MyDrive/schizconnect_COBRE_images_22498.7z'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-6050e197196b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Rename the file to .7z\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrenamed_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muploaded_file_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.7z.001'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.7z'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muploaded_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenamed_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"File renamed to: {renamed_file_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/schizconnect_COBRE_images_22498.7z.001' -> '/content/drive/MyDrive/schizconnect_COBRE_images_22498.7z'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the renamed .7z file\n",
        "!7z x \"/content/drive/MyDrive/schizconnect_COBRE_images_22498.7z\" -o\"/content/extracted_data\""
      ],
      "metadata": {
        "id": "XxGtfhUxY7JJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebf1f265-e90b-4ad1-d2d0-b08657ce44d1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (406F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan /content/drive/MyDrive/\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1 file, 2277077170 bytes (2172 MiB)\n",
            "\n",
            "Extracting archive: /content/drive/MyDrive/schizconnect_COBRE_images_22498.7z\n",
            "--\n",
            "Path = /content/drive/MyDrive/schizconnect_COBRE_images_22498.7z\n",
            "Type = 7z\n",
            "Physical Size = 2277077170\n",
            "Headers Size = 13601\n",
            "Method = LZMA2:24\n",
            "Solid = +\n",
            "Blocks = 2\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b  0% 308 - COBRE/sub-A00000368/ses-20110 . 20110101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  2% 329 - COBRE/sub-A00000541/ses-201001 . 00000541_ses-20100101_scans.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  4% 349 - COBRE/sub-A00000838/ses-20100 . 20100101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  4% 350 - COBRE/sub-A00000838/ses-201001 . 00000838_ses-20100101_scans.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  7% 372 - COBRE/sub-A00001181/ses-20100 . 20100101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  9% 404 - COBRE/sub-A00001452/ses-20100 . 20100101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 11% 425 - COBRE/sub-A00004507/ses-20120 . 20120101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 12% 425 - COBRE/sub-A00004507/ses-20120 . 20120101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 12% 436 - COBRE/sub-A00006754/ses-2011010 . 101_task-rest_run-01_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 13% 438 - COBRE/sub-A00006754/ses-2011010 . 101_task-rest_run-02_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 14% 438 - COBRE/sub-A00006754/ses-2011010 . 101_task-rest_run-02_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 14% 439 - COBRE/sub-A00006754/ses-201101 . 00006754_ses-20110101_scans.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 15% 458 - COBRE/sub-A00009280/ses-2011010 . 101_task-rest_run-01_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 15% 460 - COBRE/sub-A00009280/ses-2011010 . 101_task-rest_run-02_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 16% 460 - COBRE/sub-A00009280/ses-2011010 . 101_task-rest_run-02_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 16% 472 - COBRE/sub-A00009656/ses-20110 . 20110101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 17% 482 - COBRE/sub-A00012767/ses-20100 . 20100101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20% 502 - COBRE/sub-A00014590/ses-20110 . 20110101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 22% 522 - COBRE/sub-A00014636/ses-20090 . 20090101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 23% 525 - COBRE/sub-A00014719/ses-20120 . 20120101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 24% 525 - COBRE/sub-A00014719/ses-20120 . 20120101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 25% 543 - COBRE/sub-A00014830/ses-20090 . 20090101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 26% 553 - COBRE/sub-A00015201/ses-20110 . 20110101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 27% 563 - COBRE/sub-A00015518/ses-20100 . 20100101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 28% 573 - COBRE/sub-A00015648/ses-20110 . 20110101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 29% 573 - COBRE/sub-A00015648/ses-20110 . 20110101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 31% 604 - COBRE/sub-A00016720/ses-20110 . 20110101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 33% 632 - COBRE/sub-A00017147/ses-2011010 . 101_task-rest_run-01_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 35% 644 - COBRE/sub-A00018129/ses-20100 . 20100101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 36% 644 - COBRE/sub-A00018129/ses-20100 . 20100101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 37% 655 - COBRE/sub-A00018129/ses-20110 . 20110101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 37% 665 - COBRE/sub-A00018317/ses-20100 . 20100101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 38% 665 - COBRE/sub-A00018317/ses-20100 . 20100101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 38% 685 - COBRE/sub-A00018403/ses-2011010 . 101_task-rest_run-01_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 39% 687 - COBRE/sub-A00018403/ses-2011010 . 101_task-rest_run-02_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 40% 687 - COBRE/sub-A00018403/ses-2011010 . 101_task-rest_run-02_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 42% 701 - COBRE/sub-A00018598/ses-201001 . 00018598_ses-20100101_scans.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 44% 733 - COBRE/sub-A00019293/ses-20100 . 20100101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 46% 751 - COBRE/sub-A00019750/ses-20120 . 20120101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 47% 761 - COBRE/sub-A00020414/ses-20100 . 20100101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 48% 773 - COBRE/sub-A00020416/ses-20100 . 20100101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 49% 784 - COBRE/sub-A00020416/ses-20110 . 20110101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 50% 784 - COBRE/sub-A00020416/ses-20110 . 20110101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 51% 798 - COBRE/sub-A00020602/ses-20110 . 20110101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 52% 798 - COBRE/sub-A00020602/ses-20110 . 20110101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 53% 809 - COBRE/sub-A00020787/ses-201001 . 00020787_ses-20100101_scans.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 54% 839 - COBRE/sub-A00021598/ses-2011010 . 101_task-rest_run-01_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 55% 841 - COBRE/sub-A00021598/ses-2011010 . 101_task-rest_run-02_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 55% 842 - COBRE/sub-A00021598/ses-201101 . 00021598_ses-20110101_scans.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 56% 851 - COBRE/sub-A00022500/ses-20100 . 20100101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 57% 861 - COBRE/sub-A00023158/ses-20090 . 20090101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 58% 871 - COBRE/sub-A00023243/ses-20090 . 20090101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 58% 872 - COBRE/sub-A00023243/ses-200901 . 00023243_ses-20090101_scans.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 59% 882 - COBRE/sub-A00023246/ses-20110 . 20110101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 59% 883 - COBRE/sub-A00023246/ses-201101 . 00023246_ses-20110101_scans.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 61% 902 - COBRE/sub-A00023750/ses-20090 . 20090101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 61% 903 - COBRE/sub-A00023750/ses-200901 . 00023750_ses-20090101_scans.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 62% 905 - COBRE/sub-A00024198/ses-20090 . 20090101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 62% 906 - COBRE/sub-A00024198/ses-200901 . 00024198_ses-20090101_scans.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 63% 908 - COBRE/sub-A00024228/ses-20090 . 20090101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 64% 918 - COBRE/sub-A00024510/ses-20090 . 20090101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 64% 919 - COBRE/sub-A00024510/ses-200901 . 00024510_ses-20090101_scans.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 65% 928 - COBRE/sub-A00024568/ses-20090 . 20090101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 66% 938 - COBRE/sub-A00024684/ses-20100 . 20100101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 67% 941 - COBRE/sub-A00024953/ses-20090 . 20090101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 67% 951 - COBRE/sub-A00024959/ses-20090 . 20090101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 68% 951 - COBRE/sub-A00024959/ses-20090 . 20090101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 68% 961 - COBRE/sub-A00027119/ses-20100 . 20100101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 69% 973 - COBRE/sub-A00027391/ses-20110 . 20110101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 70% 984 - COBRE/sub-A00027410/ses-20120 . 20120101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 71% 984 - COBRE/sub-A00027410/ses-20120 . 20120101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 72% 994 - COBRE/sub-A00027537/ses-20110 . 20110101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 73% 1005 - COBRE/sub-A00027755/ses-2011010 . 101_task-rest_run-01_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 73% 1007 - COBRE/sub-A00027755/ses-2011010 . 101_task-rest_run-02_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 75% 1017 - COBRE/sub-A00027969/ses-20110 . 20110101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 75% 1018 - COBRE/sub-A00027969/ses-201101 . 00027969_ses-20110101_scans.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 75% 1028 - COBRE/sub-A00028189/ses-20120 . 20120101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 76% 1038 - COBRE/sub-A00028303/ses-20120 . 20120101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 77% 1038 - COBRE/sub-A00028303/ses-20120 . 20120101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 79% 1058 - COBRE/sub-A00028404/ses-20110 . 20110101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 79% 1059 - COBRE/sub-A00028404/ses-201101 . 00028404_ses-20110101_scans.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 82% 1090 - COBRE/sub-A00028805/ses-20120 . 20120101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 82% 1101 - COBRE/sub-A00028806/ses-20120 . 20120101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 83% 1101 - COBRE/sub-A00028806/ses-20120 . 20120101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 84% 1107 - COBRE/sub-A00031186/ses-20120 . 20120101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 86% 1111 - COBRE/sub-A00031271/ses-201201 . 00031271_ses-20120101_scans.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 86% 1113 - COBRE/sub-A00031597/ses-20120 . 20120101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 89% 1119 - COBRE/sub-A00035003/ses-20120 . 20120101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 91% 1125 - COBRE/sub-A00035836/ses-20130 . 20130101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 93% 1134 - COBRE/sub-A00037224/ses-20130 . 20130101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 94% 1134 - COBRE/sub-A00037224/ses-20130 . 20130101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 94% 1137 - COBRE/sub-A00037619/ses-20130 . 20130101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 95% 1137 - COBRE/sub-A00037619/ses-20130 . 20130101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 96% 1143 - COBRE/sub-A00037854/ses-20130 . 20130101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 98% 1146 - COBRE/sub-A00038172/ses-20130 . 20130101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 99% 1152 - COBRE/sub-A00038624/ses-20130 . 20130101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
            "\n",
            "Folders: 293\n",
            "Files: 861\n",
            "Size:       2284871048\n",
            "Compressed: 2277077170\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List the extracted files\n",
        "'''for root, dirs, files in os.walk(output_dir):\n",
        "    for file in files:\n",
        "        print(os.path.join(root, file))'''\n",
        "\n",
        "save_dir = '/content/fmri/corrected_nifti_data/'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "process_dir = '/content/fmri/processed_imaging_data/'\n",
        "os.makedirs(process_dir, exist_ok=True)\n",
        "\n",
        "spatial_maps_dir = '/content/fmri/spatial_maps_data/'\n",
        "os.makedirs(spatial_maps_dir, exist_ok=True)\n",
        "ica = CanICA(n_components=20, mask_strategy='background')\n",
        "scaler = StandardScaler()"
      ],
      "metadata": {
        "id": "m1uzobgFZDWM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "from nilearn.image import resample_img, resample_to_img, smooth_img, clean_img\n",
        "from nilearn.masking import compute_brain_mask\n",
        "from nilearn.input_data import NiftiMasker\n",
        "from nilearn.datasets import load_mni152_template\n",
        "from skimage.registration import phase_cross_correlation\n",
        "from scipy.ndimage import shift\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from joblib import Parallel, delayed\n",
        "from nilearn.maskers import NiftiMasker\n",
        "from nilearn.decomposition import CanICA\n",
        "\n",
        "# Initialize scaler globally for reuse\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Motion Correction Function\n",
        "def motion_correction(fmri_data, reference_volume=None):\n",
        "    if reference_volume is None:\n",
        "        reference_volume = np.mean(fmri_data[:5], axis=0)  # Use average of first 5 volumes as reference\n",
        "\n",
        "    corrected_images = [reference_volume]\n",
        "    reference_volume /= np.max(reference_volume)\n",
        "\n",
        "    for i in range(1, fmri_data.shape[0]):\n",
        "        fmri_data[i] /= np.max(fmri_data[i])\n",
        "        fmri_data[i] = np.nan_to_num(fmri_data[i])\n",
        "        shift_values, _, _ = phase_cross_correlation(reference_volume, fmri_data[i])\n",
        "        corrected_image = shift(fmri_data[i], shift_values)\n",
        "        corrected_images.append(corrected_image)\n",
        "\n",
        "    corrected_data = np.stack(corrected_images, axis=0)\n",
        "    return corrected_data\n",
        "\n",
        "# Feature Extraction Function\n",
        "def extract_features(nifti_img, save_dir, process_dir, i):\n",
        "    #print(f\"Processing file {i + 1}/{len(nifti_files)}: {nifti_img}\")\n",
        "    fmri_data = nifti_img.get_fdata()\n",
        "\n",
        "    # Step 1: Motion Correction\n",
        "    corrected_data = motion_correction(fmri_data)\n",
        "    corrected_data[corrected_data < 0] = 0  # Set negative values to zero\n",
        "    corrected_nifti_img = nib.Nifti1Image(corrected_data, nifti_img.affine)\n",
        "\n",
        "\n",
        "    # Load the MNI template\n",
        "    mni_template = load_mni152_template()\n",
        "    downsampled_template = resample_img(\n",
        "        mni_template,\n",
        "        target_affine=corrected_nifti_img.affine,\n",
        "        target_shape=corrected_nifti_img.shape[:3],\n",
        "        interpolation=\"linear\",\n",
        "        force_resample=True,\n",
        "        copy_header=True,\n",
        "    )\n",
        "\n",
        "    # Resample to template\n",
        "    normalized_img = resample_to_img(corrected_nifti_img, downsampled_template, interpolation=\"linear\", force_resample=True, copy_header=True)\n",
        "\n",
        "    #print(\"Min:\", np.min(normalized_img.get_fdata()), \"Max:\", np.max(normalized_img.get_fdata()), \"Mean:\", np.mean(normalized_img.get_fdata()))\n",
        "    # Compute brain mask and resample\n",
        "    #brain_mask = compute_brain_mask(normalized_img, lower_cutoff=0.3, upper_cutoff=0.8)\n",
        "    brain_mask = mni_template.get_fdata() > 0  # Threshold the template to create a binary mask\n",
        "    brain_mask_img = nib.Nifti1Image(brain_mask.astype(np.uint8), mni_template.affine)\n",
        "\n",
        "\n",
        "    resampled_mask = resample_to_img(brain_mask_img, normalized_img, interpolation=\"nearest\", force_resample=True, copy_header=True)\n",
        "\n",
        "    # Clean the image\n",
        "    cleaned_img = clean_img(\n",
        "        normalized_img,\n",
        "        detrend=True,\n",
        "        standardize=True,\n",
        "        low_pass=0.2,\n",
        "        high_pass=0.005,\n",
        "        t_r=1.0,\n",
        "        mask_img=resampled_mask,\n",
        "        n_jobs=-1,\n",
        "    )\n",
        "\n",
        "    #print(\"Min:\", np.min(cleaned_img.get_fdata()), \"Max:\", np.max(cleaned_img.get_fdata()))\n",
        "    # Smooth the image\n",
        "    smoothed_img = smooth_img(cleaned_img, fwhm=6)\n",
        "    print(smoothed_img.shape)\n",
        "    fmri_4d_data = smoothed_img.get_fdata()  # Shape: (time_points, x_dim, y_dim, z_dim)\n",
        "    print(fmri_4d_data.shape)\n",
        "\n",
        "    # Compute the total number of voxels (x_dim * y_dim * z_dim)\n",
        "\n",
        "    # Create a NiftiMasker\n",
        "    num_voxels = np.prod(fmri_4d_data.shape[:3])  # Spatial dimensions (x, y, z)\n",
        "    print(num_voxels)\n",
        "    masker = NiftiMasker(standardize=True)\n",
        "\n",
        "    # Fit the masker to your cleaned and smoothed 4D NIfTI image\n",
        "    masker.fit(smoothed_img)\n",
        "    #print(\"BYE\", time_series_data.shape)\n",
        "\n",
        "    data_2d = masker.transform(smoothed_img)  # Shape: (time_points, voxels)\n",
        "    # Initialize ICA\n",
        "    ica = CanICA(\n",
        "        n_components=50,         # Number of components\n",
        "        random_state=0,         # For reproducibility\n",
        "        high_pass=0.24999970197677612,\n",
        "        memory=\"nilearn_cache\",  # Use same cache\n",
        "        t_r=2.0,\n",
        "        mask=masker.mask_img_  # Use the mask from NiftiMasker\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    # Fit ICA with the 4D NIfTI image\n",
        "    ica.fit(smoothed_img)\n",
        "\n",
        "    # Get the spatial components\n",
        "    components = ica.components_\n",
        "\n",
        "    # Spatial maps and feature extraction\n",
        "    feature_vectors = []\n",
        "    # Save the spatial components as individual NIfTI files\n",
        "\n",
        "    mask = masker.mask_img_\n",
        "    mask_data = mask.get_fdata()\n",
        "    component_full = np.zeros(smoothed_img.shape[:3])\n",
        "    for j, component in enumerate(components):\n",
        "        # Create a NIfTI image for each component\n",
        "        # Reshape the 1D component back into 3D space (matching the fmri data shape)\n",
        "        #print(\"component shape\", component.size)\n",
        "\n",
        "        voxel_indices = np.where(mask_data != 0)  # This gives the coordinates (i, j, k) of non-zero mask voxels\n",
        "\n",
        "        # Place the component values into the correct 3D positions according to the mask\n",
        "        component_full[voxel_indices] = component  # Assign the component values to the mask positions\n",
        "        # Define a threshold dynamically based on data\n",
        "        threshold = np.mean(component_full) + np.std(component_full)\n",
        "\n",
        "        # Create binary mask\n",
        "        binary_mask = (component_full > threshold).astype(int)\n",
        "        binary_mask = binary_mask.astype(np.int32)  # Convert to int32\n",
        "\n",
        "\n",
        "        # Generate spatial map\n",
        "        spatial_map = nib.Nifti1Image(binary_mask, smoothed_img.affine)\n",
        "\n",
        "        masker = NiftiMasker(mask_img=spatial_map, standardize=True)\n",
        "        try:\n",
        "          # Debugging: Check before applying the masker\n",
        "          print(\"Checking masker...\")\n",
        "          mask_d = spatial_map.get_fdata()\n",
        "          if np.count_nonzero(mask_d) == 0:\n",
        "              raise ValueError(\"Computed mask is empty. Adjust the mask computation.\")\n",
        "\n",
        "          print(\"Checking smoothed image...\")\n",
        "          img_data = smoothed_img.get_fdata()\n",
        "          if np.isnan(img_data).sum() > 0:\n",
        "              print(\"Warning: NaN values found in smoothed image!\")\n",
        "              img_data = np.nan_to_num(img_data)\n",
        "          if np.count_nonzero(img_data) == 0:\n",
        "              raise ValueError(\"Smoothed image is empty. Verify preprocessing steps.\")\n",
        "\n",
        "          # Apply transformation\n",
        "          print(\"Applying masker transformation...\")\n",
        "          time_series = masker.fit_transform(smoothed_img)\n",
        "          print(\"Time series data shape:\", time_series.shape)\n",
        "\n",
        "        except Exception as e:\n",
        "          print(\"Error during masker transformation:\", e)\n",
        "\n",
        "        #time_series = masker.fit_transform(smoothed_img)\n",
        "\n",
        "        # Normalize time series\n",
        "        time_series = scaler.fit_transform(time_series)\n",
        "\n",
        "        # Compute voxel features\n",
        "        voxel_means = np.mean(time_series, axis=0)\n",
        "        voxel_stds = np.std(time_series, axis=0)\n",
        "\n",
        "        # Combine into feature vector\n",
        "        features = np.concatenate([voxel_means, voxel_stds])\n",
        "        feature_vectors.append(features)\n",
        "\n",
        "    return feature_vectors\n",
        "\n",
        "# Main Processing Loop\n",
        "def process_nifti_files(nifti_files, save_dir, process_dir):\n",
        "    '''results = Parallel(n_jobs=-1)(\n",
        "        delayed(extract_features)(nib.load(nii_file), save_dir, process_dir, i)\n",
        "        for i, nii_file in enumerate(nifti_files)\n",
        "    )'''\n",
        "    results = []\n",
        "    for i, nii_file in enumerate(nifti_files):\n",
        "      if i<=30:\n",
        "        print(f\"Processing file {i + 1}/{len(nifti_files)}: {nii_file}\")\n",
        "        results.append(extract_features(nib.load(nii_file), save_dir, process_dir, i))\n",
        "        #for i, nii_file in enumerate(nifti_files)'''\n",
        "    return results\n",
        "\n",
        "    return results\n",
        "nifti_file_path = '/content/extracted_data/COBRE/sub*/ses*/func/*.nii.gz'\n",
        "\n",
        "# Glob all files\n",
        "nifti_files = glob.glob(nifti_file_path)\n",
        "# Debugging step to print the files being processed\n",
        "def is_empty_nifti(file_path):\n",
        "    img = nib.load(file_path)\n",
        "    return np.count_nonzero(img.get_fdata()) == 0  # Check if data is empty\n",
        "\n",
        "nifti_files = glob.glob(nifti_file_path)\n",
        "nifti_files = [f for f in nifti_files if not is_empty_nifti(f)]\n",
        "def is_valid_nifti(file_path):\n",
        "    try:\n",
        "        nib.load(file_path)\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {file_path}: {e}\")\n",
        "        return False\n",
        "\n",
        "nifti_files = glob.glob(nifti_file_path)\n",
        "nifti_files = [f for f in nifti_files if is_valid_nifti(f)]\n",
        "\n",
        "print(\"NIfTI files found:\", nifti_files)\n",
        "\n",
        "# Run the pipeline\n",
        "feature_vectors = process_nifti_files(nifti_files, save_dir, process_dir)\n",
        "\n",
        "print(\"Preprocessing complete!\")\n"
      ],
      "metadata": {
        "id": "N79JpJbbZyl4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "581b4465-bbab-43c5-dc79-33b3a5167d9e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NIfTI files found: ['/content/extracted_data/COBRE/sub-A00028405/ses-20120101/func/sub-A00028405_ses-20120101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00014590/ses-20110101/func/sub-A00014590_ses-20110101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00014830/ses-20090101/func/sub-A00014830_ses-20090101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00002480/ses-20110101/func/sub-A00002480_ses-20110101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00001452/ses-20100101/func/sub-A00001452_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00028404/ses-20110101/func/sub-A00028404_ses-20110101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00024959/ses-20090101/func/sub-A00024959_ses-20090101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00015648/ses-20110101/func/sub-A00015648_ses-20110101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00024953/ses-20090101/func/sub-A00024953_ses-20090101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00023590/ses-20100101/func/sub-A00023590_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00016720/ses-20100101/func/sub-A00016720_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00016720/ses-20110101/func/sub-A00016720_ses-20110101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00023158/ses-20090101/func/sub-A00023158_ses-20090101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00035859/ses-20120101/func/sub-A00035859_ses-20120101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00016723/ses-20100101/func/sub-A00016723_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00020787/ses-20100101/func/sub-A00020787_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00028408/ses-20120101/func/sub-A00028408_ses-20120101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00000541/ses-20100101/func/sub-A00000541_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00000541/ses-20110101/func/sub-A00000541_ses-20110101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00014719/ses-20120101/func/sub-A00014719_ses-20120101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00024198/ses-20090101/func/sub-A00024198_ses-20090101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00037854/ses-20130101/func/sub-A00037854_ses-20130101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00000456/ses-20090101/func/sub-A00000456_ses-20090101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00027119/ses-20100101/func/sub-A00027119_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00028805/ses-20120101/func/sub-A00028805_ses-20120101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00018598/ses-20100101/func/sub-A00018598_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00035836/ses-20130101/func/sub-A00035836_ses-20130101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00027537/ses-20110101/func/sub-A00027537_ses-20110101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00038441/ses-20130101/func/sub-A00038441_ses-20130101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00028806/ses-20120101/func/sub-A00028806_ses-20120101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00037649/ses-20130101/func/sub-A00037649_ses-20130101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00028189/ses-20120101/func/sub-A00028189_ses-20120101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00000368/ses-20110101/func/sub-A00000368_ses-20110101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00014175/ses-20110101/func/sub-A00014175_ses-20110101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00001243/ses-20110101/func/sub-A00001243_ses-20110101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00023243/ses-20090101/func/sub-A00023243_ses-20090101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00001251/ses-20110101/func/sub-A00001251_ses-20110101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00021598/ses-20110101/func/sub-A00021598_ses-20110101_task-rest_run-02_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00021598/ses-20110101/func/sub-A00021598_ses-20110101_task-rest_run-01_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00009280/ses-20110101/func/sub-A00009280_ses-20110101_task-rest_run-01_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00009280/ses-20110101/func/sub-A00009280_ses-20110101_task-rest_run-02_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00006754/ses-20110101/func/sub-A00006754_ses-20110101_task-rest_run-01_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00006754/ses-20110101/func/sub-A00006754_ses-20110101_task-rest_run-02_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00020416/ses-20100101/func/sub-A00020416_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00020416/ses-20110101/func/sub-A00020416_ses-20110101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00028402/ses-20120101/func/sub-A00028402_ses-20120101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00019349/ses-20100101/func/sub-A00019349_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00021591/ses-20110101/func/sub-A00021591_ses-20110101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00031186/ses-20120101/func/sub-A00031186_ses-20120101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00000838/ses-20100101/func/sub-A00000838_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00015518/ses-20100101/func/sub-A00015518_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00027755/ses-20110101/func/sub-A00027755_ses-20110101_task-rest_run-02_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00027755/ses-20110101/func/sub-A00027755_ses-20110101_task-rest_run-01_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00019750/ses-20120101/func/sub-A00019750_ses-20120101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00034273/ses-20120101/func/sub-A00034273_ses-20120101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00014636/ses-20090101/func/sub-A00014636_ses-20090101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00028303/ses-20120101/func/sub-A00028303_ses-20120101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00018979/ses-20100101/func/sub-A00018979_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00018979/ses-20110101/func/sub-A00018979_ses-20110101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00027391/ses-20110101/func/sub-A00027391_ses-20110101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00031597/ses-20120101/func/sub-A00031597_ses-20120101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00020414/ses-20100101/func/sub-A00020414_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00018434/ses-20100101/func/sub-A00018434_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00014607/ses-20100101/func/sub-A00014607_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00018403/ses-20110101/func/sub-A00018403_ses-20110101_task-rest_run-01_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00018403/ses-20110101/func/sub-A00018403_ses-20110101_task-rest_run-02_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00019293/ses-20100101/func/sub-A00019293_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00018129/ses-20100101/func/sub-A00018129_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00018129/ses-20110101/func/sub-A00018129_ses-20110101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00037224/ses-20130101/func/sub-A00037224_ses-20130101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00024684/ses-20100101/func/sub-A00024684_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00015201/ses-20110101/func/sub-A00015201_ses-20110101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00014804/ses-20090101/func/sub-A00014804_ses-20090101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00012767/ses-20100101/func/sub-A00012767_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00018317/ses-20100101/func/sub-A00018317_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00038624/ses-20130101/func/sub-A00038624_ses-20130101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00035003/ses-20120101/func/sub-A00035003_ses-20120101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00016197/ses-20090101/func/sub-A00016197_ses-20090101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00023750/ses-20090101/func/sub-A00023750_ses-20090101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00037034/ses-20130101/func/sub-A00037034_ses-20130101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00004507/ses-20120101/func/sub-A00004507_ses-20120101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00001181/ses-20100101/func/sub-A00001181_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00024510/ses-20090101/func/sub-A00024510_ses-20090101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00035485/ses-20120101/func/sub-A00035485_ses-20120101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00027969/ses-20110101/func/sub-A00027969_ses-20110101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00037619/ses-20130101/func/sub-A00037619_ses-20130101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00009656/ses-20110101/func/sub-A00009656_ses-20110101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00013216/ses-20110101/func/sub-A00013216_ses-20110101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00022500/ses-20100101/func/sub-A00022500_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00027410/ses-20120101/func/sub-A00027410_ses-20120101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00038172/ses-20130101/func/sub-A00038172_ses-20130101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00020602/ses-20100101/func/sub-A00020602_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00020602/ses-20110101/func/sub-A00020602_ses-20110101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00024228/ses-20090101/func/sub-A00024228_ses-20090101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00024568/ses-20090101/func/sub-A00024568_ses-20090101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00000909/ses-20110101/func/sub-A00000909_ses-20110101_task-rest_run-02_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00000909/ses-20110101/func/sub-A00000909_ses-20110101_task-rest_run-01_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00017147/ses-20110101/func/sub-A00017147_ses-20110101_task-rest_run-02_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00017147/ses-20110101/func/sub-A00017147_ses-20110101_task-rest_run-01_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00031271/ses-20120101/func/sub-A00031271_ses-20120101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00023246/ses-20110101/func/sub-A00023246_ses-20110101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00029486/ses-20120101/func/sub-A00029486_ses-20120101_task-rest_bold.nii.gz']\n",
            "Processing file 1/102: /content/extracted_data/COBRE/sub-A00028405/ses-20120101/func/sub-A00028405_ses-20120101_task-rest_bold.nii.gz\n",
            "(64, 64, 33, 150)\n",
            "(64, 64, 33, 150)\n",
            "135168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/nilearn/decomposition/_base.py:492: UserWarning: memory_level is currently set to 0 but a Memory object has been provided. Setting memory_level to 1.\n",
            "  self.masker_.fit()\n",
            "/usr/local/lib/python3.11/dist-packages/nilearn/decomposition/canica.py:292: UserWarning: memory_level is currently set to 0 but a Memory object has been provided. Setting memory_level to 1.\n",
            "  components = _MultiPCA._raw_fit(self, data)\n",
            "<ipython-input-7-ad76adb94955>:115: FutureWarning: The nifti_maps_masker_ attribute is deprecated andwill be removed in Nilearn 0.11.3. Please use maps_masker_ instead.\n",
            "  ica.fit(smoothed_img)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 428)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 391)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 384)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 366)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 412)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 435)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 445)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 425)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 439)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 444)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 424)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 416)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 462)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 423)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 422)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 344)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 318)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 108)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 438)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 454)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 410)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 374)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 461)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 301)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 408)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 429)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 395)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 427)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 436)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 444)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 403)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 438)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 391)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 444)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 421)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 418)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 435)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 429)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 284)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 432)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 415)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 439)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 408)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 436)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 420)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 451)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 424)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 446)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 436)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 461)\n",
            "Processing file 2/102: /content/extracted_data/COBRE/sub-A00014590/ses-20110101/func/sub-A00014590_ses-20110101_task-rest_bold.nii.gz\n",
            "(64, 64, 33, 150)\n",
            "(64, 64, 33, 150)\n",
            "135168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/nilearn/decomposition/_base.py:492: UserWarning: memory_level is currently set to 0 but a Memory object has been provided. Setting memory_level to 1.\n",
            "  self.masker_.fit()\n",
            "/usr/local/lib/python3.11/dist-packages/nilearn/decomposition/canica.py:292: UserWarning: memory_level is currently set to 0 but a Memory object has been provided. Setting memory_level to 1.\n",
            "  components = _MultiPCA._raw_fit(self, data)\n",
            "<ipython-input-7-ad76adb94955>:115: FutureWarning: The nifti_maps_masker_ attribute is deprecated andwill be removed in Nilearn 0.11.3. Please use maps_masker_ instead.\n",
            "  ica.fit(smoothed_img)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 490)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 443)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 468)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 472)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 513)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 448)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 517)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 498)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 498)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 439)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 500)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 485)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 470)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 912)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 477)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 461)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 455)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 454)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 417)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 462)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 453)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 505)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 465)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 467)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 520)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 506)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 489)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 454)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 477)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 569)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 397)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 336)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 1098)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 451)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 479)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 425)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 495)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 524)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 477)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 451)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 531)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 464)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 416)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 423)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 525)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 511)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 506)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 579)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 1075)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 99)\n",
            "Processing file 3/102: /content/extracted_data/COBRE/sub-A00014830/ses-20090101/func/sub-A00014830_ses-20090101_task-rest_bold.nii.gz\n",
            "(64, 64, 33, 150)\n",
            "(64, 64, 33, 150)\n",
            "135168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/nilearn/decomposition/_base.py:492: UserWarning: memory_level is currently set to 0 but a Memory object has been provided. Setting memory_level to 1.\n",
            "  self.masker_.fit()\n",
            "/usr/local/lib/python3.11/dist-packages/nilearn/decomposition/canica.py:292: UserWarning: memory_level is currently set to 0 but a Memory object has been provided. Setting memory_level to 1.\n",
            "  components = _MultiPCA._raw_fit(self, data)\n",
            "<ipython-input-7-ad76adb94955>:115: FutureWarning: The nifti_maps_masker_ attribute is deprecated andwill be removed in Nilearn 0.11.3. Please use maps_masker_ instead.\n",
            "  ica.fit(smoothed_img)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 406)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 444)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 475)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 488)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 398)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 138)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 387)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 471)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 478)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 434)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 434)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 422)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 442)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 720)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 447)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 761)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 462)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 724)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 471)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 378)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 459)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 464)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 391)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 481)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 918)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 456)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 456)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 457)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 482)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 451)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 401)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 442)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 459)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 442)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 455)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 428)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 445)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 427)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 459)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 428)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 430)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 474)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 421)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 424)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 485)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 419)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 436)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 434)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 433)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 414)\n",
            "Processing file 4/102: /content/extracted_data/COBRE/sub-A00002480/ses-20110101/func/sub-A00002480_ses-20110101_task-rest_bold.nii.gz\n",
            "(64, 64, 33, 150)\n",
            "(64, 64, 33, 150)\n",
            "135168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/nilearn/decomposition/_base.py:492: UserWarning: memory_level is currently set to 0 but a Memory object has been provided. Setting memory_level to 1.\n",
            "  self.masker_.fit()\n",
            "/usr/local/lib/python3.11/dist-packages/nilearn/decomposition/canica.py:292: UserWarning: memory_level is currently set to 0 but a Memory object has been provided. Setting memory_level to 1.\n",
            "  components = _MultiPCA._raw_fit(self, data)\n",
            "<ipython-input-7-ad76adb94955>:115: FutureWarning: The nifti_maps_masker_ attribute is deprecated andwill be removed in Nilearn 0.11.3. Please use maps_masker_ instead.\n",
            "  ica.fit(smoothed_img)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 370)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 373)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 428)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 463)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 455)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 415)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 576)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 466)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 403)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 172)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 443)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 424)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 383)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 423)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 307)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 413)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 434)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 439)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 489)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 389)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 435)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 369)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 411)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 383)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 368)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 390)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 461)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 416)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 467)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 419)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 463)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 448)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 442)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 375)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 393)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 446)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 331)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 790)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 394)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 431)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 410)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 356)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 87)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 429)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 376)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 491)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 425)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 458)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 328)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 529)\n",
            "Processing file 5/102: /content/extracted_data/COBRE/sub-A00001452/ses-20100101/func/sub-A00001452_ses-20100101_task-rest_bold.nii.gz\n",
            "(64, 64, 33, 150)\n",
            "(64, 64, 33, 150)\n",
            "135168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/nilearn/decomposition/_base.py:492: UserWarning: memory_level is currently set to 0 but a Memory object has been provided. Setting memory_level to 1.\n",
            "  self.masker_.fit()\n",
            "/usr/local/lib/python3.11/dist-packages/nilearn/decomposition/canica.py:292: UserWarning: memory_level is currently set to 0 but a Memory object has been provided. Setting memory_level to 1.\n",
            "  components = _MultiPCA._raw_fit(self, data)\n",
            "<ipython-input-7-ad76adb94955>:115: FutureWarning: The nifti_maps_masker_ attribute is deprecated andwill be removed in Nilearn 0.11.3. Please use maps_masker_ instead.\n",
            "  ica.fit(smoothed_img)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 118)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 338)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 322)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 387)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 505)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 397)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 395)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 525)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 438)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 459)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 477)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 468)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 487)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 462)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 494)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 506)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 465)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 476)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 477)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 452)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 470)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 530)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 467)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 482)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 504)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 446)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 432)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 404)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 438)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 519)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 447)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 492)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 401)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 454)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 433)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 443)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 466)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 568)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 369)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 467)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 489)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 441)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 713)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 397)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 514)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 853)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 494)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 424)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 564)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 452)\n",
            "Processing file 6/102: /content/extracted_data/COBRE/sub-A00028404/ses-20110101/func/sub-A00028404_ses-20110101_task-rest_bold.nii.gz\n",
            "(64, 64, 33, 150)\n",
            "(64, 64, 33, 150)\n",
            "135168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/nilearn/decomposition/_base.py:492: UserWarning: memory_level is currently set to 0 but a Memory object has been provided. Setting memory_level to 1.\n",
            "  self.masker_.fit()\n",
            "/usr/local/lib/python3.11/dist-packages/nilearn/decomposition/canica.py:292: UserWarning: memory_level is currently set to 0 but a Memory object has been provided. Setting memory_level to 1.\n",
            "  components = _MultiPCA._raw_fit(self, data)\n",
            "<ipython-input-7-ad76adb94955>:115: FutureWarning: The nifti_maps_masker_ attribute is deprecated andwill be removed in Nilearn 0.11.3. Please use maps_masker_ instead.\n",
            "  ica.fit(smoothed_img)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 1306)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 454)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 474)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 424)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 520)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 446)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 457)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 481)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 477)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 1097)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 432)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 410)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 144)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 447)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 440)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 478)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 434)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 465)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 450)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 423)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 444)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 483)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 457)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 417)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 473)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 1169)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 461)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 464)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 444)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 438)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 473)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 426)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 430)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 1276)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 489)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 439)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 429)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 408)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 449)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 473)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 1427)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 452)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 442)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 374)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 465)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 454)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 1223)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 448)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 424)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 434)\n",
            "Processing file 7/102: /content/extracted_data/COBRE/sub-A00024959/ses-20090101/func/sub-A00024959_ses-20090101_task-rest_bold.nii.gz\n",
            "(64, 64, 33, 150)\n",
            "(64, 64, 33, 150)\n",
            "135168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/nilearn/decomposition/_base.py:492: UserWarning: memory_level is currently set to 0 but a Memory object has been provided. Setting memory_level to 1.\n",
            "  self.masker_.fit()\n",
            "/usr/local/lib/python3.11/dist-packages/nilearn/decomposition/canica.py:292: UserWarning: memory_level is currently set to 0 but a Memory object has been provided. Setting memory_level to 1.\n",
            "  components = _MultiPCA._raw_fit(self, data)\n",
            "<ipython-input-7-ad76adb94955>:115: FutureWarning: The nifti_maps_masker_ attribute is deprecated andwill be removed in Nilearn 0.11.3. Please use maps_masker_ instead.\n",
            "  ica.fit(smoothed_img)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 540)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 441)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 507)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 529)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 456)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 492)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 514)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 509)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 484)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 495)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 501)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 473)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 357)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 523)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 423)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 522)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 197)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 474)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 545)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 470)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 484)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 405)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 458)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 496)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 499)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 345)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 492)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 454)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 954)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 487)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 549)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 493)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 548)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 791)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 370)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 501)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 453)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 585)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 492)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 197)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 456)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 442)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 519)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 560)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 503)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 417)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 467)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 476)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 380)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 473)\n",
            "Processing file 8/102: /content/extracted_data/COBRE/sub-A00015648/ses-20110101/func/sub-A00015648_ses-20110101_task-rest_bold.nii.gz\n",
            "(64, 64, 33, 150)\n",
            "(64, 64, 33, 150)\n",
            "135168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/nilearn/decomposition/_base.py:492: UserWarning: memory_level is currently set to 0 but a Memory object has been provided. Setting memory_level to 1.\n",
            "  self.masker_.fit()\n",
            "/usr/local/lib/python3.11/dist-packages/nilearn/decomposition/canica.py:292: UserWarning: memory_level is currently set to 0 but a Memory object has been provided. Setting memory_level to 1.\n",
            "  components = _MultiPCA._raw_fit(self, data)\n",
            "<ipython-input-7-ad76adb94955>:115: FutureWarning: The nifti_maps_masker_ attribute is deprecated andwill be removed in Nilearn 0.11.3. Please use maps_masker_ instead.\n",
            "  ica.fit(smoothed_img)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 469)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 408)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 87)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 455)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 374)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 464)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 519)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 313)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 456)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 515)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 500)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 486)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 500)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 508)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 418)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 442)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 509)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 889)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 499)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 534)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 516)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 491)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 212)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 493)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 516)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 511)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 481)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 465)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 467)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 461)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 322)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 503)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 612)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 486)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 883)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 453)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 535)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 500)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 546)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 415)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 526)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 517)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 435)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 502)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 509)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 493)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 563)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 384)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 444)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 523)\n",
            "Processing file 9/102: /content/extracted_data/COBRE/sub-A00024953/ses-20090101/func/sub-A00024953_ses-20090101_task-rest_bold.nii.gz\n",
            "(64, 64, 33, 150)\n",
            "(64, 64, 33, 150)\n",
            "135168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/nilearn/decomposition/_base.py:492: UserWarning: memory_level is currently set to 0 but a Memory object has been provided. Setting memory_level to 1.\n",
            "  self.masker_.fit()\n",
            "/usr/local/lib/python3.11/dist-packages/nilearn/decomposition/canica.py:292: UserWarning: memory_level is currently set to 0 but a Memory object has been provided. Setting memory_level to 1.\n",
            "  components = _MultiPCA._raw_fit(self, data)\n",
            "<ipython-input-7-ad76adb94955>:115: FutureWarning: The nifti_maps_masker_ attribute is deprecated andwill be removed in Nilearn 0.11.3. Please use maps_masker_ instead.\n",
            "  ica.fit(smoothed_img)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 457)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 98)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 446)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 430)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 477)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 478)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 413)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 328)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 459)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 287)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 434)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 467)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 498)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 410)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 480)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 460)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 477)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 450)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 430)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 503)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 424)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 406)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 427)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 471)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 496)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 486)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 474)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 486)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 443)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 434)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 448)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 467)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 113)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 403)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 441)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 475)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 513)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 474)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 446)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 482)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 492)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 405)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 455)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 463)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 504)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 422)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 451)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 458)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 454)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 305)\n",
            "Processing file 10/102: /content/extracted_data/COBRE/sub-A00023590/ses-20100101/func/sub-A00023590_ses-20100101_task-rest_bold.nii.gz\n",
            "(64, 64, 33, 150)\n",
            "(64, 64, 33, 150)\n",
            "135168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/nilearn/decomposition/_base.py:492: UserWarning: memory_level is currently set to 0 but a Memory object has been provided. Setting memory_level to 1.\n",
            "  self.masker_.fit()\n",
            "/usr/local/lib/python3.11/dist-packages/nilearn/decomposition/canica.py:292: UserWarning: memory_level is currently set to 0 but a Memory object has been provided. Setting memory_level to 1.\n",
            "  components = _MultiPCA._raw_fit(self, data)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-ad76adb94955>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;31m# Run the pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m \u001b[0mfeature_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_nifti_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnifti_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Preprocessing complete!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-ad76adb94955>\u001b[0m in \u001b[0;36mprocess_nifti_files\u001b[0;34m(nifti_files, save_dir, process_dir)\u001b[0m\n\u001b[1;32m    194\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Processing file {i + 1}/{len(nifti_files)}: {nii_file}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnii_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0;31m#for i, nii_file in enumerate(nifti_files)'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-ad76adb94955>\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(nifti_img, save_dir, process_dir, i)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;31m# Fit ICA with the 4D NIfTI image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0mica\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmoothed_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;31m# Get the spatial components\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nilearn/decomposition/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, imgs, y, confounds)\u001b[0m\n\u001b[1;32m    506\u001b[0m             \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m         )\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;31m# Create and fit appropriate MapsMasker for transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nilearn/decomposition/canica.py\u001b[0m in \u001b[0;36m_raw_fit\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    291\u001b[0m             )\n\u001b[1;32m    292\u001b[0m         \u001b[0mcomponents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_MultiPCA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unmix_components\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nilearn/decomposition/canica.py\u001b[0m in \u001b[0;36m_unmix_components\u001b[0;34m(self, components)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mseeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;31m# Note: fastICA is very unstable, hence we use 64bit on it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         results = Parallel(n_jobs=self.n_jobs, verbose=self.verbose)(\n\u001b[0m\u001b[1;32m    214\u001b[0m             delayed(self._cache(fastica, func_memory_level=2))(\n\u001b[1;32m    215\u001b[0m                 \u001b[0mcomponents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/decomposition/_fastica.py\u001b[0m in \u001b[0;36mfastica\u001b[0;34m(X, n_components, algorithm, whiten, fun, fun_args, max_iter, tol, w_init, whiten_solver, random_state, return_X_mean, compute_sources, return_n_iter)\u001b[0m\n\u001b[1;32m    347\u001b[0m     )\n\u001b[1;32m    348\u001b[0m     \u001b[0mest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m     \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_sources\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_sources\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhiten\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"unit-variance\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"arbitrary-variance\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/decomposition/_fastica.py\u001b[0m in \u001b[0;36m_fit_transform\u001b[0;34m(self, X, compute_sources)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"parallel\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m             \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ica_par\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"deflation\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m             \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ica_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/decomposition/_fastica.py\u001b[0m in \u001b[0;36m_ica_par\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mp_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mgwtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_wtx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0mW1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sym_decorrelation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgwtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mp_\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mg_wtx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mgwtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_wtx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/decomposition/_fastica.py\u001b[0m in \u001b[0;36m_cube\u001b[0;34m(x, fun_args)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_cube\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# ... (Your previous code) ...\n",
        "\n",
        "# Ensure all feature vectors are NumPy arrays and have the same length\n",
        "#feature_vectors = [np.array(f) for f in feature_vectors]\n",
        "\n",
        "# Find the maximum feature vector length\n",
        "max_length = max(len(sublist) for f in feature_vectors for sublist in f)  # Modified to find max length across all sublists\n",
        "\n",
        "# Pad all vectors to the same length\n",
        "X = np.array([[np.pad(sublist, (0, max_length - len(sublist)), mode='constant')\n",
        "              for sublist in f] for f in feature_vectors])  # Pad each sublist\n",
        "\n",
        "print(\"Final feature matrix shape:\", X.shape)  # Should be (num_samples, max_length)\n",
        "\n",
        "# ... (Rest of your code) ..."
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "dgrJ-esf5lmU",
        "outputId": "358ce2e8-8842-41ea-a475-743fdf9ea737"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'feature_vectors' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-deba5f065f46>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Find the maximum feature vector length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmax_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msublist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeature_vectors\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msublist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Modified to find max length across all sublists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Pad all vectors to the same length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'feature_vectors' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "\n",
        "# Define Autoencoder class\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, input_dim, latent_dim):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, latent_dim)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, input_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return encoded, decoded\n",
        "\n",
        "# Initialize Autoencoder\n",
        "print(X.shape, X.shape[0], X.shape[1])\n",
        "input_dim = X.shape[2]  # Ensure correct shape after padding\n",
        "latent_dim = 32\n",
        "autoencoder = Autoencoder(input_dim, latent_dim)\n",
        "\n",
        "# Set up optimizer and loss function\n",
        "optimizer = optim.Adam(autoencoder.parameters(), lr=1e-3)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Convert X to a PyTorch tensor\n",
        "X_tensor = torch.FloatTensor(X)\n",
        "\n",
        "# Train Autoencoder\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    autoencoder.train()\n",
        "    optimizer.zero_grad()\n",
        "    encoded, decoded = autoencoder(X_tensor)\n",
        "    loss = criterion(decoded, X_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Extract latent features\n",
        "autoencoder.eval()\n",
        "with torch.no_grad():\n",
        "    fmri_features, _ = autoencoder(X_tensor)\n",
        "\n",
        "# Convert features to NumPy for clustering\n",
        "fmri_features_np = fmri_features.numpy()\n",
        "print('dim', fmri_features_np.shape)\n",
        "# Apply K-Means Clustering\n",
        "n_clusters = 2  # Choose the number of clusters\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "# Reshape to ensure it's (num_samples, latent_dim)\n",
        "fmri_features_np = fmri_features_np.reshape(fmri_features_np.shape[0], -1)\n",
        "cluster_labels = kmeans.fit_predict(fmri_features_np)\n",
        "\n",
        "print(\"Cluster Labels:\", cluster_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2quj0tnv51tg",
        "outputId": "f6592cf0-7ba9-4aad-fcf8-8ee12a57a6d8"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(22, 50, 2586) 22 50\n",
            "Epoch [10/100], Loss: 0.1099\n",
            "Epoch [20/100], Loss: 0.0437\n",
            "Epoch [30/100], Loss: 0.0304\n",
            "Epoch [40/100], Loss: 0.0215\n",
            "Epoch [50/100], Loss: 0.0165\n",
            "Epoch [60/100], Loss: 0.0140\n",
            "Epoch [70/100], Loss: 0.0123\n",
            "Epoch [80/100], Loss: 0.0109\n",
            "Epoch [90/100], Loss: 0.0098\n",
            "Epoch [100/100], Loss: 0.0089\n",
            "dim (22, 50, 32)\n",
            "Cluster Labels: [0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "# Define paths\n",
        "uploaded_file_path = '/content/drive/MyDrive/dataverse_files.zip'\n",
        "data_dir = '/content/extracted_eeg_data'\n",
        "os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "# Extract the contents of the zip file\n",
        "with zipfile.ZipFile(uploaded_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(data_dir)\n",
        "print(\"Google Drive mounted and paths defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbzvjzbS56Wp",
        "outputId": "f7a96031-466d-49d9-fef4-fbe45b2d2c92"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Google Drive mounted and paths defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "!pip install mne\n",
        "from mne.io import read_raw_edf\n",
        "from mne import Epochs, pick_types\n",
        "from mne.time_frequency import psd_array_welch\n",
        "\n",
        "# Directory containing .edf files\n",
        "output_dir = \"/content/eeg_features/\"\n",
        "\n",
        "# Create output directory if it doesn't exist\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Feature extraction function\n",
        "def extract_features(raw, output_file, label):\n",
        "    # Select EEG channels only\n",
        "    raw.pick_types(eeg=True)\n",
        "\n",
        "    # Preprocessing: Filter data (e.g., bandpass filter between 0.5-50 Hz)\n",
        "    raw.filter(0.5, 50., fir_design='firwin')\n",
        "\n",
        "    # Divide raw data into epochs (e.g., 2-second windows)\n",
        "    events = np.array([[i, 0, 1] for i in range(0, int(raw.n_times), int(raw.info['sfreq'] * 2))])\n",
        "    event_id = {'Epoch': 1}\n",
        "    epochs = Epochs(raw, events, event_id, tmin=0, tmax=2, baseline=None, preload=True)\n",
        "\n",
        "    # Compute power spectral density (PSD) for each epoch\n",
        "    psds, freqs = psd_array_welch(\n",
        "        epochs.get_data(),  # Raw data as a NumPy array\n",
        "        sfreq=raw.info['sfreq'],  # Sampling frequency\n",
        "        fmin=0.5,  # Minimum frequency\n",
        "        fmax=50.,  # Maximum frequency\n",
        "        n_fft=256  # FFT size\n",
        "    )\n",
        "\n",
        "    # Compute band-specific power features (delta, theta, alpha, beta, gamma)\n",
        "    bands = {\n",
        "        \"delta\": (0.5, 4),\n",
        "        \"theta\": (4, 8),\n",
        "        \"alpha\": (8, 12),\n",
        "        \"beta\": (12, 30),\n",
        "        \"gamma\": (30, 50)\n",
        "    }\n",
        "    features = []\n",
        "    for band, (low, high) in bands.items():\n",
        "        band_mask = (freqs >= low) & (freqs < high)  # Create mask for the band\n",
        "        if np.sum(band_mask) == 0:  # Ensure the mask has valid frequencies\n",
        "            raise ValueError(f\"No frequencies found in the band {band}: ({low}-{high} Hz)\")\n",
        "        band_power = psds[:, :, band_mask].mean(axis=-1)  # Mean power for the band\n",
        "        features.append(band_power)\n",
        "\n",
        "    # Concatenate all features into a single feature vector\n",
        "    features = np.hstack(features)  # Concatenate features into a 2D array\n",
        "    labels = np.full((features.shape[0], 1), label)  # Shape: (num_epochs, 1)\n",
        "\n",
        "    # Concatenate labels with features\n",
        "    labeled_features = np.hstack([features, labels])  # Shape: (num_epochs, num_features + 1)\n",
        "\n",
        "    print(f\"Shape of features: {features.shape}, Label: {label}, Final shape: {labeled_features.shape}\")\n",
        "\n",
        "    # Save features to a file\n",
        "    try:\n",
        "        np.save(output_file, labeled_features)\n",
        "        print(f\"Saved features to {output_file}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to save features for file {file_name}: {e}\")\n",
        "# Loop through all .edf files in the directory\n",
        "for file_name in os.listdir(data_dir):\n",
        "    if file_name.endswith(\".edf\"):\n",
        "        file_path = os.path.join(data_dir, file_name)\n",
        "        print(f\"Processing file: {file_path}\")\n",
        "\n",
        "        try:\n",
        "            # Load the EDF file\n",
        "            raw = read_raw_edf(file_path, preload=True)\n",
        "            # Extract label from the filename (custom logic based on your dataset)\n",
        "            if file_name.startswith('h'):\n",
        "                label = 0  # Healthy\n",
        "            elif file_name.startswith('s'):\n",
        "                label = 1  # Sick\n",
        "            else:\n",
        "                print(f\"Skipping file {file_name} as no label mapping is defined.\")\n",
        "                continue  # Skip files with unknown labels\n",
        "            print(f\"Assigned label {label} for file {file_name}\")\n",
        "            # Extract features and save to output directory\n",
        "            output_file = os.path.join(output_dir, f\"{os.path.splitext(file_name)[0]}_features.npy\")\n",
        "            extract_features(raw, output_file, label=label)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing file {file_name}: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9BT3nNUOnti",
        "outputId": "bdbd8646-2d43-4e44-d6b6-412b2edebd7a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mne\n",
            "  Downloading mne-1.9.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mne) (3.1.5)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.11/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from mne) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mne) (24.2)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.11/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from mne) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (2.32.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6->mne) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.1.31)\n",
            "Downloading mne-1.9.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mne\n",
            "Successfully installed mne-1.9.0\n",
            "Processing file: /content/extracted_eeg_data/s05.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/s05.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 222499  =      0.000 ...   889.996 secs...\n",
            "Assigned label 1 for file s05.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "445 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 445 events and 501 original time points ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n",
            "Shape of features: (444, 95), Label: 1, Final shape: (444, 96)\n",
            "Saved features to /content/eeg_features/s05_features.npy\n",
            "Processing file: /content/extracted_eeg_data/s03.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/s03.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 240999  =      0.000 ...   963.996 secs...\n",
            "Assigned label 1 for file s03.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "482 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 482 events and 501 original time points ...\n",
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (481, 95), Label: 1, Final shape: (481, 96)\n",
            "Saved features to /content/eeg_features/s03_features.npy\n",
            "Processing file: /content/extracted_eeg_data/h08.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/h08.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 227499  =      0.000 ...   909.996 secs...\n",
            "Assigned label 0 for file h08.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "455 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 455 events and 501 original time points ...\n",
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (454, 95), Label: 0, Final shape: (454, 96)\n",
            "Saved features to /content/eeg_features/h08_features.npy\n",
            "Processing file: /content/extracted_eeg_data/h01.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/h01.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 231249  =      0.000 ...   924.996 secs...\n",
            "Assigned label 0 for file h01.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "463 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 463 events and 501 original time points ...\n",
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (462, 95), Label: 0, Final shape: (462, 96)\n",
            "Saved features to /content/eeg_features/h01_features.npy\n",
            "Processing file: /content/extracted_eeg_data/h10.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/h10.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 278749  =      0.000 ...  1114.996 secs...\n",
            "Assigned label 0 for file h10.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "558 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 558 events and 501 original time points ...\n",
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (557, 95), Label: 0, Final shape: (557, 96)\n",
            "Saved features to /content/eeg_features/h10_features.npy\n",
            "Processing file: /content/extracted_eeg_data/s10.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/s10.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 212499  =      0.000 ...   849.996 secs...\n",
            "Assigned label 1 for file s10.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "425 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 425 events and 501 original time points ...\n",
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (424, 95), Label: 1, Final shape: (424, 96)\n",
            "Saved features to /content/eeg_features/s10_features.npy\n",
            "Processing file: /content/extracted_eeg_data/s06.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/s06.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 184999  =      0.000 ...   739.996 secs...\n",
            "Assigned label 1 for file s06.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "370 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 370 events and 501 original time points ...\n",
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (369, 95), Label: 1, Final shape: (369, 96)\n",
            "Saved features to /content/eeg_features/s06_features.npy\n",
            "Processing file: /content/extracted_eeg_data/h09.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/h09.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 226249  =      0.000 ...   904.996 secs...\n",
            "Assigned label 0 for file h09.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "453 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 453 events and 501 original time points ...\n",
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (452, 95), Label: 0, Final shape: (452, 96)\n",
            "Saved features to /content/eeg_features/h09_features.npy\n",
            "Processing file: /content/extracted_eeg_data/h06.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/h06.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 232499  =      0.000 ...   929.996 secs...\n",
            "Assigned label 0 for file h06.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "465 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 465 events and 501 original time points ...\n",
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (464, 95), Label: 0, Final shape: (464, 96)\n",
            "Saved features to /content/eeg_features/h06_features.npy\n",
            "Processing file: /content/extracted_eeg_data/h02.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/h02.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 227499  =      0.000 ...   909.996 secs...\n",
            "Assigned label 0 for file h02.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "455 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 455 events and 501 original time points ...\n",
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (454, 95), Label: 0, Final shape: (454, 96)\n",
            "Saved features to /content/eeg_features/h02_features.npy\n",
            "Processing file: /content/extracted_eeg_data/s08.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/s08.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 227749  =      0.000 ...   910.996 secs...\n",
            "Assigned label 1 for file s08.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "456 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 456 events and 501 original time points ...\n",
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (455, 95), Label: 1, Final shape: (455, 96)\n",
            "Saved features to /content/eeg_features/s08_features.npy\n",
            "Processing file: /content/extracted_eeg_data/h11.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/h11.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 228749  =      0.000 ...   914.996 secs...\n",
            "Assigned label 0 for file h11.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "458 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 458 events and 501 original time points ...\n",
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (457, 95), Label: 0, Final shape: (457, 96)\n",
            "Saved features to /content/eeg_features/h11_features.npy\n",
            "Processing file: /content/extracted_eeg_data/s14.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/s14.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 542499  =      0.000 ...  2169.996 secs...\n",
            "Assigned label 1 for file s14.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "1085 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 1085 events and 501 original time points ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n",
            "Shape of features: (1084, 95), Label: 1, Final shape: (1084, 96)\n",
            "Saved features to /content/eeg_features/s14_features.npy\n",
            "Processing file: /content/extracted_eeg_data/s13.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/s13.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 283749  =      0.000 ...  1134.996 secs...\n",
            "Assigned label 1 for file s13.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "568 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 568 events and 501 original time points ...\n",
            "1 bad epochs dropped\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Effective window size : 1.024 (s)\n",
            "Shape of features: (567, 95), Label: 1, Final shape: (567, 96)\n",
            "Saved features to /content/eeg_features/s13_features.npy\n",
            "Processing file: /content/extracted_eeg_data/s12.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/s12.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 271749  =      0.000 ...  1086.996 secs...\n",
            "Assigned label 1 for file s12.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "544 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 544 events and 501 original time points ...\n",
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (543, 95), Label: 1, Final shape: (543, 96)\n",
            "Saved features to /content/eeg_features/s12_features.npy\n",
            "Processing file: /content/extracted_eeg_data/s07.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/s07.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 336499  =      0.000 ...  1345.996 secs...\n",
            "Assigned label 1 for file s07.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "673 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 673 events and 501 original time points ...\n",
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (672, 95), Label: 1, Final shape: (672, 96)\n",
            "Saved features to /content/eeg_features/s07_features.npy\n",
            "Processing file: /content/extracted_eeg_data/h05.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/h05.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 236249  =      0.000 ...   944.996 secs...\n",
            "Assigned label 0 for file h05.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "473 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 473 events and 501 original time points ...\n",
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (472, 95), Label: 0, Final shape: (472, 96)\n",
            "Saved features to /content/eeg_features/h05_features.npy\n",
            "Processing file: /content/extracted_eeg_data/h14.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/h14.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 216249  =      0.000 ...   864.996 secs...\n",
            "Assigned label 0 for file h14.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "433 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 433 events and 501 original time points ...\n",
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (432, 95), Label: 0, Final shape: (432, 96)\n",
            "Saved features to /content/eeg_features/h14_features.npy\n",
            "Processing file: /content/extracted_eeg_data/s09.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/s09.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 296249  =      0.000 ...  1184.996 secs...\n",
            "Assigned label 1 for file s09.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "593 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 593 events and 501 original time points ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n",
            "Shape of features: (592, 95), Label: 1, Final shape: (592, 96)\n",
            "Saved features to /content/eeg_features/s09_features.npy\n",
            "Processing file: /content/extracted_eeg_data/s11.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/s11.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 339999  =      0.000 ...  1359.996 secs...\n",
            "Assigned label 1 for file s11.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "680 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 680 events and 501 original time points ...\n",
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (679, 95), Label: 1, Final shape: (679, 96)\n",
            "Saved features to /content/eeg_features/s11_features.npy\n",
            "Processing file: /content/extracted_eeg_data/h13.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/h13.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 241249  =      0.000 ...   964.996 secs...\n",
            "Assigned label 0 for file h13.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "483 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 483 events and 501 original time points ...\n",
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (482, 95), Label: 0, Final shape: (482, 96)\n",
            "Saved features to /content/eeg_features/h13_features.npy\n",
            "Processing file: /content/extracted_eeg_data/h03.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/h03.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 227499  =      0.000 ...   909.996 secs...\n",
            "Assigned label 0 for file h03.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "455 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 455 events and 501 original time points ...\n",
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (454, 95), Label: 0, Final shape: (454, 96)\n",
            "Saved features to /content/eeg_features/h03_features.npy\n",
            "Processing file: /content/extracted_eeg_data/s04.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/s04.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 301249  =      0.000 ...  1204.996 secs...\n",
            "Assigned label 1 for file s04.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "603 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 603 events and 501 original time points ...\n",
            "1 bad epochs dropped\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Effective window size : 1.024 (s)\n",
            "Shape of features: (602, 95), Label: 1, Final shape: (602, 96)\n",
            "Saved features to /content/eeg_features/s04_features.npy\n",
            "Processing file: /content/extracted_eeg_data/h12.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/h12.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 224999  =      0.000 ...   899.996 secs...\n",
            "Assigned label 0 for file h12.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "450 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 450 events and 501 original time points ...\n",
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (449, 95), Label: 0, Final shape: (449, 96)\n",
            "Saved features to /content/eeg_features/h12_features.npy\n",
            "Processing file: /content/extracted_eeg_data/s01.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/s01.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 211249  =      0.000 ...   844.996 secs...\n",
            "Assigned label 1 for file s01.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "423 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 423 events and 501 original time points ...\n",
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (422, 95), Label: 1, Final shape: (422, 96)\n",
            "Saved features to /content/eeg_features/s01_features.npy\n",
            "Processing file: /content/extracted_eeg_data/h07.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/h07.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 227499  =      0.000 ...   909.996 secs...\n",
            "Assigned label 0 for file h07.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "455 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 455 events and 501 original time points ...\n",
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (454, 95), Label: 0, Final shape: (454, 96)\n",
            "Saved features to /content/eeg_features/h07_features.npy\n",
            "Processing file: /content/extracted_eeg_data/h04.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/h04.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 231249  =      0.000 ...   924.996 secs...\n",
            "Assigned label 0 for file h04.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "463 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 463 events and 501 original time points ...\n",
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (462, 95), Label: 0, Final shape: (462, 96)\n",
            "Saved features to /content/eeg_features/h04_features.npy\n",
            "Processing file: /content/extracted_eeg_data/s02.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/s02.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 286249  =      0.000 ...  1144.996 secs...\n",
            "Assigned label 1 for file s02.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "573 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 573 events and 501 original time points ...\n",
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (572, 95), Label: 1, Final shape: (572, 96)\n",
            "Saved features to /content/eeg_features/s02_features.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Load features from saved .npy files\n",
        "def load_features(data_dir):\n",
        "    feature_list = []\n",
        "    labels_list = []\n",
        "\n",
        "    # Ensure to use the correct directory variable (output_dir)\n",
        "    for file_name in os.listdir(data_dir):\n",
        "        if file_name.endswith(\"_features.npy\"):  # Make sure we are looking at the correct files\n",
        "            file_path = os.path.join(data_dir, file_name)\n",
        "            try:\n",
        "                features = np.load(file_path)\n",
        "                feature_list.append(features[:, :-1])  # Exclude labels (everything except the last column)\n",
        "                labels_list.append(features[:, -1])   # Labels are the last column (single column)\n",
        "\n",
        "                print(f\"Loaded {file_name}: features shape {features[:, :-1].shape}, labels shape {features[:, -1].shape}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {file_name}: {e}\")\n",
        "\n",
        "    # Concatenate all features and labels from all files\n",
        "    X = np.vstack(feature_list)  # Feature matrix (all rows, all feature columns)\n",
        "    y = np.hstack(labels_list)   # Label vector (all labels)\n",
        "\n",
        "    # Print the shapes of the final feature matrix and label vector\n",
        "    print(f\"Final shape of features matrix (X): {X.shape}\")\n",
        "    print(f\"Final shape of labels vector (y): {y.shape}\")\n",
        "\n",
        "    return X, y\n",
        "\n",
        "\n",
        "# Directory containing EEG feature files\n",
        "output_dir = \"/content/eeg_features/\"\n",
        "X, y = load_features(output_dir)\n",
        "\n",
        "# Split into training and testing sets\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Assuming X and y are already loaded correctly\n",
        "# X: Features matrix (shape: 14411, 95)\n",
        "# y: Labels vector (shape: 14411,)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "ss = StandardScaler()\n",
        "X_train = ss.fit_transform(X_train)  # Fit & transform on train\n",
        "X_test = ss.transform(X_test)\n",
        "\n",
        "def add_noise(X, noise_level=0.01):\n",
        "    noise = noise_level * np.random.randn(*X.shape)\n",
        "    return X + noise\n",
        "\n",
        "X_train_noisy = add_noise(X_train, noise_level=0.02)\n",
        "X_train_combined = np.vstack((X_train, X_train_noisy))\n",
        "y_train_combined = np.hstack((y_train, y_train))  # Duplicate labels\n",
        "\n",
        "# Convert to tensors again\n",
        "X_train_combined = torch.tensor(X_train_combined, dtype=torch.float32)\n",
        "y_train_combined = torch.tensor(y_train_combined, dtype=torch.long)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# Create DataLoader for batching and shuffling\n",
        "train_data = TensorDataset(X_train_combined, y_train_combined)\n",
        "test_data = TensorDataset(X_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
        "\n",
        "# Define the model\n",
        "class EEGModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(EEGModel, self).__init__()\n",
        "        self.eeg_branch = nn.Sequential(\n",
        "            nn.Linear(input_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),  # Dropout for regularization\n",
        "            nn.Linear(256, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, output_dim)  # Output layer for classification (2 classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.eeg_branch(x)\n",
        "\n",
        "# Initialize the model\n",
        "model = EEGModel(input_dim=X.shape[1], hidden_dim=256, output_dim=2)  # Adjust hidden_dim as needed\n",
        "\n",
        "# Define loss function and optimizer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
        "\n",
        "# Update the loss function with class weights\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop (use the same code you already have)\n",
        "# Training loop (use the same code you already have)\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "# Add learning rate scheduler\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5, verbose=True)\n",
        "\n",
        "# Modify training loop\n",
        "best_loss = float('inf')\n",
        "for epoch in range(100):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        inputs, labels = batch\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch+1}, Loss: {avg_loss}\")\n",
        "\n",
        "    # Check for early stopping\n",
        "    if avg_loss < best_loss:\n",
        "        best_loss = avg_loss\n",
        "        torch.save(model.state_dict(), 'best_model.pth')  # Save best model\n",
        "    else:\n",
        "        print(\"No improvement, applying LR scheduler\")\n",
        "        scheduler.step(avg_loss)  # Reduce learning rate if loss stops improving\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
        "\n",
        "# Ensure model is in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Store predictions and ground truth labels\n",
        "y_true = []\n",
        "y_pred = []\n",
        "y_probs = []  # For probability scores\n",
        "\n",
        "# Disable gradient computation for evaluation\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        inputs, labels = batch\n",
        "        outputs = model(inputs)  # Get raw logits\n",
        "        probs = torch.softmax(outputs, dim=1)[:, 1]  # Convert to probabilities (class 1)\n",
        "        _, predicted = torch.max(outputs, 1)  # Get class with highest score\n",
        "\n",
        "        y_true.extend(labels.numpy())  # Actual labels\n",
        "        y_pred.extend(predicted.numpy())  # Predicted labels\n",
        "        y_probs.extend(probs.numpy())  # Probability scores\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "y_true = np.array(y_true)\n",
        "y_pred = np.array(y_pred)\n",
        "y_probs = np.array(y_probs)\n",
        "\n",
        "# Compute evaluation metrics\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "classification_rep = classification_report(y_true, y_pred)\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "roc_auc = roc_auc_score(y_true, y_probs)\n",
        "TN, FP, FN, TP = confusion_matrix(y_true, y_pred).ravel()\n",
        "\n",
        "print('True Positive(TP)  = ', TP)\n",
        "print('False Positive(FP) = ', FP)\n",
        "print('True Negative(TN)  = ', TN)\n",
        "print('False Negative(FN) = ', FN)\n",
        "# Print results\n",
        "print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\n🔹 Classification Report:\\n\", classification_rep)\n",
        "print(\"\\n🔹 Confusion Matrix:\\n\", conf_matrix)\n",
        "print(f\"\\n🔹 ROC-AUC Score: {roc_auc:.4f}\")\n",
        "accuracy =  (TP + TN) / (TP + FP + TN + FN)\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "print(f\"🔹 F1 Score: {f1:.4f}\")\n",
        "print('Accuracy of the binary classifier = {:0.3f}'.format(accuracy))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ursYlTkKROAL",
        "outputId": "8cc51e93-6ed2-4146-ff4b-b0503e52828a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded h11_features.npy: features shape (457, 95), labels shape (457,)\n",
            "Loaded h13_features.npy: features shape (482, 95), labels shape (482,)\n",
            "Loaded h05_features.npy: features shape (472, 95), labels shape (472,)\n",
            "Loaded h10_features.npy: features shape (557, 95), labels shape (557,)\n",
            "Loaded s07_features.npy: features shape (672, 95), labels shape (672,)\n",
            "Loaded s02_features.npy: features shape (572, 95), labels shape (572,)\n",
            "Loaded h12_features.npy: features shape (449, 95), labels shape (449,)\n",
            "Loaded s08_features.npy: features shape (455, 95), labels shape (455,)\n",
            "Loaded h07_features.npy: features shape (454, 95), labels shape (454,)\n",
            "Loaded h04_features.npy: features shape (462, 95), labels shape (462,)\n",
            "Loaded h06_features.npy: features shape (464, 95), labels shape (464,)\n",
            "Loaded s05_features.npy: features shape (444, 95), labels shape (444,)\n",
            "Loaded h08_features.npy: features shape (454, 95), labels shape (454,)\n",
            "Loaded s11_features.npy: features shape (679, 95), labels shape (679,)\n",
            "Loaded s03_features.npy: features shape (481, 95), labels shape (481,)\n",
            "Loaded h02_features.npy: features shape (454, 95), labels shape (454,)\n",
            "Loaded s13_features.npy: features shape (567, 95), labels shape (567,)\n",
            "Loaded h01_features.npy: features shape (462, 95), labels shape (462,)\n",
            "Loaded h09_features.npy: features shape (452, 95), labels shape (452,)\n",
            "Loaded h14_features.npy: features shape (432, 95), labels shape (432,)\n",
            "Loaded h03_features.npy: features shape (454, 95), labels shape (454,)\n",
            "Loaded s04_features.npy: features shape (602, 95), labels shape (602,)\n",
            "Loaded s14_features.npy: features shape (1084, 95), labels shape (1084,)\n",
            "Loaded s01_features.npy: features shape (422, 95), labels shape (422,)\n",
            "Loaded s09_features.npy: features shape (592, 95), labels shape (592,)\n",
            "Loaded s10_features.npy: features shape (424, 95), labels shape (424,)\n",
            "Loaded s12_features.npy: features shape (543, 95), labels shape (543,)\n",
            "Loaded s06_features.npy: features shape (369, 95), labels shape (369,)\n",
            "Final shape of features matrix (X): (14411, 95)\n",
            "Final shape of labels vector (y): (14411,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.6193532003806188\n",
            "Epoch 2, Loss: 0.5349007833462495\n",
            "Epoch 3, Loss: 0.5091159825141613\n",
            "Epoch 4, Loss: 0.49207958781860284\n",
            "Epoch 5, Loss: 0.4810545054765848\n",
            "Epoch 6, Loss: 0.4688686350217232\n",
            "Epoch 7, Loss: 0.4689480081288772\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 8, Loss: 0.44927043666148325\n",
            "Epoch 9, Loss: 0.4427904313837988\n",
            "Epoch 10, Loss: 0.7227860208622803\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 11, Loss: 0.42948948517000884\n",
            "Epoch 12, Loss: 0.4222867842873878\n",
            "Epoch 13, Loss: 0.4180391402198718\n",
            "Epoch 14, Loss: 0.41050276169057426\n",
            "Epoch 15, Loss: 0.403953189327872\n",
            "Epoch 16, Loss: 0.3984912736616896\n",
            "Epoch 17, Loss: 0.39416903526296276\n",
            "Epoch 18, Loss: 0.40121010183935335\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 19, Loss: 0.38396604685388375\n",
            "Epoch 20, Loss: 0.3820242869871608\n",
            "Epoch 21, Loss: 0.3742683664316962\n",
            "Epoch 22, Loss: 0.37123640498818733\n",
            "Epoch 23, Loss: 0.3672219093382006\n",
            "Epoch 24, Loss: 0.3677579497797249\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 25, Loss: 0.35947606157092654\n",
            "Epoch 26, Loss: 0.7455100408319891\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 27, Loss: 0.3613353248619469\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 28, Loss: 0.3503061208499254\n",
            "Epoch 29, Loss: 0.36414868931269506\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 30, Loss: 0.34453688667723414\n",
            "Epoch 31, Loss: 0.34115815973846164\n",
            "Epoch 32, Loss: 0.3392905532961061\n",
            "Epoch 33, Loss: 0.33486431740092104\n",
            "Epoch 34, Loss: 0.32874567096931695\n",
            "Epoch 35, Loss: 0.33322532699834667\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 36, Loss: 0.3269174931758254\n",
            "Epoch 37, Loss: 0.3231760737370457\n",
            "Epoch 38, Loss: 0.3240221975117745\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 39, Loss: 0.31984858413243433\n",
            "Epoch 40, Loss: 0.3154670227120614\n",
            "Epoch 41, Loss: 0.3115247894497313\n",
            "Epoch 42, Loss: 0.3128621006858419\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 43, Loss: 0.30595782011218325\n",
            "Epoch 44, Loss: 0.30734720570448587\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 45, Loss: 1.0605582806926508\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 46, Loss: 0.31555157123938116\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 47, Loss: 0.3038917524222086\n",
            "Epoch 48, Loss: 0.3026121748093317\n",
            "Epoch 49, Loss: 0.2980069675036436\n",
            "Epoch 50, Loss: 0.29409312677277616\n",
            "Epoch 51, Loss: 0.29829888879018424\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 52, Loss: 0.2864146520047498\n",
            "Epoch 53, Loss: 0.2870042690863976\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 54, Loss: 0.28564422176434445\n",
            "Epoch 55, Loss: 0.2849166560807877\n",
            "Epoch 56, Loss: 0.28134751529295066\n",
            "Epoch 57, Loss: 0.2830800366913073\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 58, Loss: 0.2763993266154323\n",
            "Epoch 59, Loss: 0.28302530230149714\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 60, Loss: 0.27197201393500586\n",
            "Epoch 61, Loss: 0.2760363591934097\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 62, Loss: 0.2662748640855036\n",
            "Epoch 63, Loss: 0.2671921048423595\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 64, Loss: 0.2696827754334232\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 65, Loss: 0.26771445803829197\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 66, Loss: 0.2665991659700518\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 67, Loss: 0.25814248218074354\n",
            "Epoch 68, Loss: 0.2540848561557087\n",
            "Epoch 69, Loss: 0.26078977076524107\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 70, Loss: 0.2550768624969135\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 71, Loss: 0.28166800951199417\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 72, Loss: 0.2574092528215174\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 73, Loss: 0.3694885474734405\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 74, Loss: 0.26186025080948894\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 75, Loss: 0.23796070651454332\n",
            "Epoch 76, Loss: 0.23101615054896596\n",
            "Epoch 77, Loss: 0.2319489583240811\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 78, Loss: 0.23082753214654486\n",
            "Epoch 79, Loss: 0.22857394488252833\n",
            "Epoch 80, Loss: 0.22371199896790572\n",
            "Epoch 81, Loss: 0.22254620975203063\n",
            "Epoch 82, Loss: 0.22460594874690976\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 83, Loss: 0.22276693423824198\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 84, Loss: 0.21773931888874465\n",
            "Epoch 85, Loss: 0.21579480243945967\n",
            "Epoch 86, Loss: 0.21800860242378076\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 87, Loss: 0.21433956068031182\n",
            "Epoch 88, Loss: 0.2145797132828532\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 89, Loss: 0.20791365669147502\n",
            "Epoch 90, Loss: 0.21499845621413027\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 91, Loss: 0.21310790597334417\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 92, Loss: 0.24652779969722916\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 93, Loss: 0.2061010521324076\n",
            "Epoch 94, Loss: 0.20656771929218218\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 95, Loss: 0.20696286788794416\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 96, Loss: 0.20153770379766206\n",
            "Epoch 97, Loss: 0.20510051961569392\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 98, Loss: 0.20338905831942192\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 99, Loss: 0.19927096259973107\n",
            "Epoch 100, Loss: 0.1986057373458112\n",
            "True Positive(TP)  =  1883\n",
            "False Positive(FP) =  102\n",
            "True Negative(TN)  =  1502\n",
            "False Negative(FN) =  116\n",
            "✅ Accuracy: 0.9395\n",
            "\n",
            "🔹 Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.94      0.93      1604\n",
            "           1       0.95      0.94      0.95      1999\n",
            "\n",
            "    accuracy                           0.94      3603\n",
            "   macro avg       0.94      0.94      0.94      3603\n",
            "weighted avg       0.94      0.94      0.94      3603\n",
            "\n",
            "\n",
            "🔹 Confusion Matrix:\n",
            " [[1502  102]\n",
            " [ 116 1883]]\n",
            "\n",
            "🔹 ROC-AUC Score: 0.9803\n",
            "🔹 F1 Score: 0.9453\n",
            "Accuracy of the binary classifier = 0.939\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EEGFeatureExtractor(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, feature_dim):\n",
        "        super(EEGFeatureExtractor, self).__init__()\n",
        "        self.eeg_branch = nn.Sequential(\n",
        "            nn.Linear(input_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, hidden_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.feature_layer = nn.Linear(hidden_dim, feature_dim)  # Feature vector instead of classification\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.eeg_branch(x)  # Extract intermediate features\n",
        "        return self.feature_layer(x)  # Output feature representation"
      ],
      "metadata": {
        "id": "vYuddvpQGrCx"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eeg_model = EEGFeatureExtractor(input_dim=95, hidden_dim=256, feature_dim=64)\n",
        "pretrained_dict = torch.load('best_model.pth')  # Load saved model\n",
        "model_dict = eeg_model.state_dict()\n",
        "\n",
        "# Remove layers that have mismatched sizes (like the first Linear layer)\n",
        "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict and v.shape == model_dict[k].shape}\n",
        "\n",
        "# Update model weights\n",
        "model_dict.update(pretrained_dict)\n",
        "eeg_model.load_state_dict(model_dict, strict=False)  # strict=False allows skipping mismatched layers\n",
        "\n",
        "print(\"✅ Loaded pretrained weights, excluding mismatched layers.\")\n",
        "\n",
        "\n",
        "# Freeze the EEG model (optional)\n",
        "eeg_model.eval()  # Set to evaluation mode to avoid updating weights during training\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uis2Q8AtDFNf",
        "outputId": "c8d78fcf-860c-4ad6-cf4d-a547bab1f29c"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded pretrained weights, excluding mismatched layers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-53-1b33c9f0595d>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  pretrained_dict = torch.load('best_model.pth')  # Load saved model\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EEGFeatureExtractor(\n",
              "  (eeg_branch): Sequential(\n",
              "    (0): Linear(in_features=95, out_features=256, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
              "    (4): ReLU()\n",
              "  )\n",
              "  (feature_layer): Linear(in_features=256, out_features=64, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class FusionModel(nn.Module):\n",
        "    def __init__(self, eeg_model, fmri_dim, fusion_dim, output_dim=2):\n",
        "        super(FusionModel, self).__init__()\n",
        "\n",
        "        # Use the pretrained EEG feature extractor\n",
        "        self.eeg_branch = eeg_model\n",
        "\n",
        "        # fMRI feature extraction (assuming it's 128-dimensional features from autoencoder)\n",
        "        self.fmri_branch = nn.Linear(fmri_dim, 256)\n",
        "\n",
        "        # Fusion layer (combining EEG and fMRI features)\n",
        "        self.fusion_layer = nn.Sequential(\n",
        "            nn.Linear(320, fusion_dim),  # EEG (64) + fMRI (64) → Fusion\n",
        "            nn.BatchNorm1d(50),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(fusion_dim, output_dim) # Final classification layer (2 classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, eeg, fmri):\n",
        "        # Extract EEG features (using pretrained EEG model)\n",
        "        with torch.no_grad():\n",
        "            eeg_features = self.eeg_branch(eeg)  # Extract EEG embeddings\n",
        "\n",
        "        # Extract fMRI features\n",
        "        fmri_features = self.fmri_branch(fmri)  # Extract fMRI embeddings\n",
        "\n",
        "        # Fix mismatch in dimensions and align EEG and fMRI feature sizes\n",
        "        eeg_features = eeg_features.unsqueeze(1)  # Add extra dimension to EEG features\n",
        "        eeg_features = eeg_features.expand(-1, fmri_features.shape[1], -1)  # Match sequence length of fMRI features\n",
        "\n",
        "        # Fix batch size mismatch if needed\n",
        "        if fmri_features.shape[0] < eeg_features.shape[0]:\n",
        "            fmri_features = fmri_features.repeat((eeg_features.shape[0] // fmri_features.shape[0] + 1), 1, 1)\n",
        "            fmri_features = fmri_features[:eeg_features.shape[0]]  # Trim excess\n",
        "\n",
        "        # Combine EEG and fMRI features\n",
        "        combined_features = torch.cat((eeg_features, fmri_features), dim=2)  # Concatenate along the feature dimension\n",
        "\n",
        "        # Pass through fusion layer for final classification\n",
        "        output = self.fusion_layer(combined_features)  # Final output (logits for 2 classes)\n",
        "\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "EQafoFNCDSaq"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fusion_model = FusionModel(eeg_model=eeg_model, fmri_dim=32, fusion_dim=256, output_dim=2)\n",
        "\n",
        "optimizer = optim.Adam(fusion_model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "print(y_train_combined.shape)\n",
        "\n",
        "\n",
        "for epoch in range(50):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs = fusion_model(X_train_combined, fmri_features[:len(X_train_combined)])\n",
        "    # Ensure model output has the shape [batch_size, 2] (logits)\n",
        "    print(f\"Output shape: {outputs.shape}\")  # This should be [batch_size, 2]\n",
        "\n",
        "    # Ensure target labels are 1D [batch_size]\n",
        "    print(f\"Target shape: {y_train.shape}\")  # This should be [batch_size]\n",
        "    # Assuming the final time step's output is the relevant prediction\n",
        "    outputs = outputs[:, -1, :]  # Get the last time step (shape: [batch_size, 2])\n",
        "\n",
        "    # Now, outputs shape will be [batch_size, 2] (which is expected by CrossEntropyLoss)\n",
        "\n",
        "    loss = criterion(outputs, y_train_combined)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_48xBFPbE_D0",
        "outputId": "4aa3b7da-8dac-45db-f805-351c2cc6d020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([21616])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, f1_score\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Load EEG and fMRI features (assuming they have been loaded already)\n",
        "# X_test, y_test (EEG features and labels) are already in the previous code\n",
        "# fmri_features: This is assumed to be preloaded in a similar manner to EEG features.\n",
        "\n",
        "# Ensure model is in evaluation mode\n",
        "fusion_model.eval()\n",
        "\n",
        "# Initialize lists to store predictions and ground truth\n",
        "y_true = []\n",
        "y_pred = []\n",
        "y_probs = []  # For probability scores\n",
        "\n",
        "# Inference loop\n",
        "with torch.no_grad():\n",
        "    for i in range(0, len(X_test), 64):  # Iterate in batches of 64\n",
        "        # Slice EEG batch\n",
        "        eeg_batch = X_test[i:i+64]\n",
        "\n",
        "        # Slice fMRI batch to match EEG batch size\n",
        "        fmri_batch = fmri_features[i:i+len(eeg_batch)]  # Ensure the batch size matches\n",
        "\n",
        "        # Ensure fMRI batch is not empty\n",
        "        if fmri_batch.shape[0] == 0:\n",
        "            continue  # Skip empty batches\n",
        "\n",
        "        # Perform inference with the fusion model\n",
        "        outputs = fusion_model(eeg_batch, fmri_batch)  # Pass both EEG and fMRI data to the model\n",
        "\n",
        "        # Apply sigmoid activation to the output logits (convert to probabilities)\n",
        "        probs = torch.sigmoid(outputs)  # Apply sigmoid to get probabilities (shape: [batch_size, 2])\n",
        "\n",
        "        # Get predicted class based on sigmoid output (threshold at 0.5)\n",
        "        predicted = (probs[:, 1] > 0.5).long()  # If probability of class 1 is greater than 0.5, predict class 1, else class 0\n",
        "\n",
        "        # Store results\n",
        "        y_true.extend(y_test[i:i+len(eeg_batch)].cpu().numpy())  # Actual labels\n",
        "        y_pred.extend(predicted.cpu().numpy())  # Predicted labels\n",
        "        y_probs.extend(probs[:, 1].cpu().numpy())  # Probabilities for ROC-AUC (only for class 1)\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "y_true = np.array(y_true)\n",
        "y_pred = np.array(y_pred)\n",
        "y_probs = np.array(y_probs)\n",
        "\n",
        "# Check for empty arrays\n",
        "if len(y_true) == 0 or len(y_pred) == 0:\n",
        "    print(\"Error: y_true or y_pred is empty. Please check your inference loop.\")\n",
        "else:\n",
        "    # Ensure that y_true and y_pred are both 1D arrays with binary labels (0 or 1)\n",
        "    if y_true.ndim > 1:\n",
        "        y_true = y_true.flatten()\n",
        "    if y_pred.ndim > 1:\n",
        "        y_pred = y_pred.flatten()\n",
        "\n",
        "    # Compute evaluation metrics\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    classification_rep = classification_report(y_true, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    roc_auc = roc_auc_score(y_true, y_probs)\n",
        "\n",
        "    # Confusion matrix values\n",
        "    TN, FP, FN, TP = confusion_matrix(y_true, y_pred).ravel()\n",
        "\n",
        "    print('True Positive (TP) =', TP)\n",
        "    print('False Positive (FP) =', FP)\n",
        "    print('True Negative (TN) =', TN)\n",
        "    print('False Negative (FN) =', FN)\n",
        "\n",
        "    # Print results\n",
        "    print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
        "    print(\"\\n🔹 Classification Report:\\n\", classification_rep)\n",
        "    print(\"\\n🔹 Confusion Matrix:\\n\", conf_matrix)\n",
        "    print(f\"\\n🔹 ROC-AUC Score: {roc_auc:.4f}\")\n",
        "\n",
        "    # Calculate final accuracy\n",
        "    accuracy = (TP + TN) / (TP + FP + TN + FN)\n",
        "    print(f\"Accuracy of the binary classifier = {accuracy:.4f}\")\n",
        "\n",
        "    # Calculate F1 Score\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    print(f\"🔹 F1 Score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        },
        "id": "5OpB7WaKNLAy",
        "outputId": "d4bcc15c-7bb2-4405-ea91-ca9356c98631"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EEG Features Shape: torch.Size([64, 50, 64])\n",
            "fMRI Features Shape: torch.Size([22, 50, 64])\n",
            "64\n",
            "64\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Classification metrics can't handle a mix of binary and multiclass-multioutput targets",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-101-4452160baec9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# Compute evaluation metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mclassification_rep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mconf_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattach_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    108\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[1;32m    109\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and multiclass-multioutput targets"
          ]
        }
      ]
    }
  ]
}