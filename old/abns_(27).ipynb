{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxlW9QixK0J6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd21c44d-dc9e-45ca-9fa7-82b0ecd3cf07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "p7zip-full is already the newest version (16.02+dfsg-8).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 20 not upgraded.\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.11/dist-packages (5.3.2)\n",
            "Collecting nilearn\n",
            "  Downloading nilearn-0.11.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting dicom2nifti\n",
            "  Downloading dicom2nifti-2.5.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.11/dist-packages (from nibabel) (6.5.2)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from nibabel) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.11/dist-packages (from nibabel) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.11/dist-packages (from nibabel) (4.12.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from nilearn) (1.4.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from nilearn) (5.3.1)\n",
            "Requirement already satisfied: pandas>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from nilearn) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.25.0 in /usr/local/lib/python3.11/dist-packages (from nilearn) (2.32.3)\n",
            "Requirement already satisfied: scikit-learn>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from nilearn) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from nilearn) (1.13.1)\n",
            "Collecting pydicom>=2.2.0 (from dicom2nifti)\n",
            "  Downloading pydicom-3.0.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting python-gdcm (from dicom2nifti)\n",
            "  Downloading python_gdcm-3.0.24.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.0->nilearn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.0->nilearn) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.0->nilearn) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.25.0->nilearn) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.25.0->nilearn) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.25.0->nilearn) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.25.0->nilearn) (2025.1.31)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.0->nilearn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.2.0->nilearn) (1.17.0)\n",
            "Downloading nilearn-0.11.1-py3-none-any.whl (10.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dicom2nifti-2.5.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydicom-3.0.1-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_gdcm-3.0.24.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-gdcm, pydicom, dicom2nifti, nilearn\n",
            "Successfully installed dicom2nifti-2.5.1 nilearn-0.11.1 pydicom-3.0.1 python-gdcm-3.0.24.1\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.1)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.13.1)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (3.4.2)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (11.1.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.1.10)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "# Install p7zip-full for handling .7z archives\n",
        "!apt-get install -y p7zip-full\n",
        "!pip install nibabel nilearn dicom2nifti\n",
        "from scipy.ndimage import shift\n",
        "\n",
        "from nilearn.image import clean_img, resample_to_img\n",
        "import nibabel as nib\n",
        "import os\n",
        "import dicom2nifti\n",
        "import nibabel as nib\n",
        "from nilearn.image import clean_img, resample_to_img, smooth_img, resample_img\n",
        "from nilearn.masking import compute_brain_mask\n",
        "from nilearn.datasets import load_mni152_template\n",
        "import numpy as np\n",
        "from nilearn.decomposition import CanICA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from nilearn.connectome import ConnectivityMeasure\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Ridge\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "!pip install scikit-image\n",
        "from skimage.registration import phase_cross_correlation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define paths\n",
        "uploaded_file_path = '/content/drive/MyDrive/schizconnect_COBRE_images_22498.7z.001'\n",
        "output_dir = '/content/extracted_data'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "print(\"Google Drive mounted and paths defined.\")\n"
      ],
      "metadata": {
        "id": "xZl6tJVrYz17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d16ba3d-e85d-47f6-8e6d-5df444fc6f3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Google Drive mounted and paths defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename the file to .7z\n",
        "renamed_file_path = uploaded_file_path.replace('.7z.001', '.7z')\n",
        "os.rename(uploaded_file_path, renamed_file_path)\n",
        "\n",
        "print(f\"File renamed to: {renamed_file_path}\")\n"
      ],
      "metadata": {
        "id": "hjqZoRO7YuRD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2abb395-ff18-4851-e3af-226ce7508d6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File renamed to: /content/drive/MyDrive/schizconnect_COBRE_images_22498.7z\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the renamed .7z file\n",
        "!7z x \"/content/drive/MyDrive/schizconnect_COBRE_images_22498.7z\" -o\"/content/extracted_data\""
      ],
      "metadata": {
        "id": "XxGtfhUxY7JJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bfe8691-2c24-4540-db4d-582bc32a1fbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (406F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan /content/drive/MyDrive/\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1 file, 2277077170 bytes (2172 MiB)\n",
            "\n",
            "Extracting archive: /content/drive/MyDrive/schizconnect_COBRE_images_22498.7z\n",
            "--\n",
            "Path = /content/drive/MyDrive/schizconnect_COBRE_images_22498.7z\n",
            "Type = 7z\n",
            "Physical Size = 2277077170\n",
            "Headers Size = 13601\n",
            "Method = LZMA2:24\n",
            "Solid = +\n",
            "Blocks = 2\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b  1% 318 - COBRE/sub-A00000456/ses-20090 . 20090101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  2% 328 - COBRE/sub-A00000541/ses-20100 . 20100101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  4% 349 - COBRE/sub-A00000838/ses-20100 . 20100101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  5% 361 - COBRE/sub-A00000909/ses-2011010 . 0101_task-rest_run-02_bold.json\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  7% 372 - COBRE/sub-A00001181/ses-20100 . 20100101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  8% 384 - COBRE/sub-A00001243/ses-20110 . 20110101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  8% 385 - COBRE/sub-A00001243/ses-201101 . 00001243_ses-20110101_scans.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 10% 404 - COBRE/sub-A00001452/ses-20100 . 20100101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 12% 425 - COBRE/sub-A00004507/ses-20120 . 20120101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 13% 436 - COBRE/sub-A00006754/ses-2011010 . 101_task-rest_run-01_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 13% 437 - COBRE/sub-A00006754/ses-2011010 . 0101_task-rest_run-02_bold.json\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 14% 438 - COBRE/sub-A00006754/ses-2011010 . 101_task-rest_run-02_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 14% 458 - COBRE/sub-A00009280/ses-2011010 . 101_task-rest_run-01_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 15% 458 - COBRE/sub-A00009280/ses-2011010 . 101_task-rest_run-01_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 16% 472 - COBRE/sub-A00009656/ses-20110 . 20110101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 18% 482 - COBRE/sub-A00012767/ses-20100 . 20100101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 19% 492 - COBRE/sub-A00014175/ses-20110 . 20110101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20% 502 - COBRE/sub-A00014590/ses-20110 . 20110101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 21% 512 - COBRE/sub-A00014607/ses-20100 . 20100101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 22% 522 - COBRE/sub-A00014636/ses-20090 . 20090101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 23% 525 - COBRE/sub-A00014719/ses-20120 . 20120101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 25% 543 - COBRE/sub-A00014830/ses-20090 . 20090101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 26% 543 - COBRE/sub-A00014830/ses-20090 . 20090101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 26% 553 - COBRE/sub-A00015201/ses-20110 . 20110101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 27% 553 - COBRE/sub-A00015201/ses-20110 . 20110101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 28% 573 - COBRE/sub-A00015648/ses-20110 . 20110101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 29% 583 - COBRE/sub-A00016197/ses-20090 . 20090101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 30% 593 - COBRE/sub-A00016720/ses-20100 . 20100101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 31% 593 - COBRE/sub-A00016720/ses-20100 . 20100101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 31% 604 - COBRE/sub-A00016720/ses-20110 . 20110101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 32% 604 - COBRE/sub-A00016720/ses-20110 . 20110101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 34% 634 - COBRE/sub-A00017147/ses-2011010 . 101_task-rest_run-02_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 36% 655 - COBRE/sub-A00018129/ses-20110 . 20110101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 38% 665 - COBRE/sub-A00018317/ses-20100 . 20100101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 38% 685 - COBRE/sub-A00018403/ses-2011010 . 101_task-rest_run-01_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 39% 687 - COBRE/sub-A00018403/ses-2011010 . 101_task-rest_run-02_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 40% 687 - COBRE/sub-A00018403/ses-2011010 . 101_task-rest_run-02_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 40% 697 - COBRE/sub-A00018434/ses-20100 . 20100101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 41% 697 - COBRE/sub-A00018434/ses-20100 . 20100101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 43% 713 - COBRE/sub-A00018979/ses-201001 . 00018979_ses-20100101_scans.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 44% 733 - COBRE/sub-A00019293/ses-20100 . 20100101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 45% 733 - COBRE/sub-A00019293/ses-20100 . 20100101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 48% 773 - COBRE/sub-A00020416/ses-20100 . 20100101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 50% 787 - COBRE/sub-A00020602/ses-20100 . 20100101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 52% 808 - COBRE/sub-A00020787/ses-20100 . 20100101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 55% 839 - COBRE/sub-A00021598/ses-2011010 . 101_task-rest_run-01_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 57% 861 - COBRE/sub-A00023158/ses-20090 . 20090101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 59% 882 - COBRE/sub-A00023246/ses-20110 . 20110101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 61% 905 - COBRE/sub-A00024198/ses-20090 . 20090101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 62% 905 - COBRE/sub-A00024198/ses-20090 . 20090101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 62% 906 - COBRE/sub-A00024198/ses-200901 . 00024198_ses-20090101_scans.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 64% 918 - COBRE/sub-A00024510/ses-20090 . 20090101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 66% 938 - COBRE/sub-A00024684/ses-20100 . 20100101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 67% 941 - COBRE/sub-A00024953/ses-20090 . 20090101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 67% 951 - COBRE/sub-A00024959/ses-20090 . 20090101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 68% 951 - COBRE/sub-A00024959/ses-20090 . 20090101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 69% 962 - COBRE/sub-A00027119/ses-201001 . 00027119_ses-20100101_scans.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 70% 973 - COBRE/sub-A00027391/ses-20110 . 20110101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 70% 974 - COBRE/sub-A00027391/ses-201101 . 00027391_ses-20110101_scans.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 72% 1005 - COBRE/sub-A00027755/ses-2011010 . 101_task-rest_run-01_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 74% 1007 - COBRE/sub-A00027755/ses-2011010 . 101_task-rest_run-02_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 76% 1028 - COBRE/sub-A00028189/ses-20120 . 20120101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 77% 1038 - COBRE/sub-A00028303/ses-20120 . 20120101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 77% 1048 - COBRE/sub-A00028402/ses-20120 . 20120101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 79% 1058 - COBRE/sub-A00028404/ses-20110 . 20110101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 80% 1069 - COBRE/sub-A00028405/ses-201201 . 00028405_ses-20120101_scans.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 81% 1079 - COBRE/sub-A00028408/ses-20120 . 20120101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 81% 1080 - COBRE/sub-A00028408/ses-201201 . 00028408_ses-20120101_scans.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 83% 1104 - COBRE/sub-A00029486/ses-20120 . 20120101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 85% 1107 - COBRE/sub-A00031186/ses-20120 . 20120101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 87% 1113 - COBRE/sub-A00031597/ses-20120 . 20120101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 88% 1119 - COBRE/sub-A00035003/ses-20120 . 20120101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 89% 1122 - COBRE/sub-A00035485/ses-20120 . 20120101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 90% 1125 - COBRE/sub-A00035836/ses-20130 . 20130101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 91% 1128 - COBRE/sub-A00035859/ses-20120 . 20120101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 92% 1131 - COBRE/sub-A00037034/ses-20130 . 20130101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 93% 1134 - COBRE/sub-A00037224/ses-20130 . 20130101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 95% 1137 - COBRE/sub-A00037619/ses-20130 . 20130101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 95% 1138 - COBRE/sub-A00037619/ses-201301 . 00037619_ses-20130101_scans.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 97% 1146 - COBRE/sub-A00038172/ses-20130 . 20130101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 98% 1149 - COBRE/sub-A00038441/ses-20130 . 20130101_task-rest_bold.nii.gz\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
            "\n",
            "Folders: 293\n",
            "Files: 861\n",
            "Size:       2284871048\n",
            "Compressed: 2277077170\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List the extracted files\n",
        "'''for root, dirs, files in os.walk(output_dir):\n",
        "    for file in files:\n",
        "        print(os.path.join(root, file))'''\n",
        "\n",
        "save_dir = '/content/fmri/corrected_nifti_data/'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "process_dir = '/content/fmri/processed_imaging_data/'\n",
        "os.makedirs(process_dir, exist_ok=True)\n",
        "\n",
        "spatial_maps_dir = '/content/fmri/spatial_maps_data/'\n",
        "os.makedirs(spatial_maps_dir, exist_ok=True)\n",
        "ica = CanICA(n_components=20, mask_strategy='background')\n",
        "scaler = StandardScaler()"
      ],
      "metadata": {
        "id": "m1uzobgFZDWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "from nilearn.image import resample_img, resample_to_img, smooth_img, clean_img\n",
        "from nilearn.masking import compute_brain_mask\n",
        "from nilearn.input_data import NiftiMasker\n",
        "from nilearn.datasets import load_mni152_template\n",
        "from skimage.registration import phase_cross_correlation\n",
        "from scipy.ndimage import shift\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from joblib import Parallel, delayed\n",
        "from nilearn.maskers import NiftiMasker\n",
        "from nilearn.decomposition import CanICA\n",
        "\n",
        "# Initialize scaler globally for reuse\n",
        "scaler = StandardScaler()\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "from nilearn.image import resample_to_img, smooth_img, clean_img\n",
        "from nilearn.datasets import load_mni152_template, fetch_atlas_harvard_oxford\n",
        "from nilearn.maskers import NiftiLabelsMasker\n",
        "from nilearn.input_data import NiftiMasker\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load Harvard-Oxford Atlas (ROIs)\n",
        "ho_atlas = fetch_atlas_harvard_oxford('cort-maxprob-thr25-2mm')  # 96 cortical ROIs\n",
        "ho_masker = NiftiLabelsMasker(labels_img=ho_atlas.maps, standardize=True, detrend=True,\n",
        "                             low_pass=0.1, high_pass=0.01, t_r=2.0)\n",
        "\n",
        "def extract_roi_features(nifti_img):\n",
        "    \"\"\"Extract mean ROI time-series features from fMRI data.\"\"\"\n",
        "    # Motion correction (use Nilearn's default instead of custom)\n",
        "    # Note: If motion correction is already done, skip this step.\n",
        "    cleaned_img = clean_img(nifti_img, detrend=True, standardize=\"zscore\", t_r=2.0)\n",
        "\n",
        "    # Smoothing\n",
        "    smoothed_img = smooth_img(cleaned_img, fwhm=6)\n",
        "\n",
        "    # Extract ROI time-series (shape: [time_points, n_rois])\n",
        "    roi_time_series = ho_masker.fit_transform(smoothed_img)\n",
        "\n",
        "    # Feature engineering: Temporal variability (mean/std across time)\n",
        "    roi_means = np.mean(roi_time_series, axis=0)   # Mean activation per ROI\n",
        "    roi_stds = np.std(roi_time_series, axis=0)     # Temporal variability per ROI\n",
        "\n",
        "    # Combine into feature vector (shape: [n_samples, n_features])\n",
        "    features = np.concatenate([roi_means, roi_stds])  # 96*2 = 192 features\n",
        "\n",
        "    return features\n",
        "\n",
        "# Main processing loop (simplified)\n",
        "def process_nifti_files(nifti_files):\n",
        "    features = []\n",
        "    for i, nii_file in enumerate(nifti_files):\n",
        "        print(f\"Processing {i+1}/{len(nifti_files)}: {nii_file}\")\n",
        "        img = nib.load(nii_file)\n",
        "        features.append(extract_roi_features(img))\n",
        "    return np.array(features)\n",
        "\n",
        "nifti_file_path = '/content/extracted_data/COBRE/sub*/ses*/func/*.nii.gz'\n",
        "\n",
        "# Glob all files\n",
        "nifti_files = glob.glob(nifti_file_path)\n",
        "# Debugging step to print the files being processed\n",
        "def is_empty_nifti(file_path):\n",
        "    img = nib.load(file_path)\n",
        "    return np.count_nonzero(img.get_fdata()) == 0  # Check if data is empty\n",
        "\n",
        "nifti_files = glob.glob(nifti_file_path)\n",
        "nifti_files = [f for f in nifti_files if not is_empty_nifti(f)]\n",
        "def is_valid_nifti(file_path):\n",
        "    try:\n",
        "        nib.load(file_path)\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {file_path}: {e}\")\n",
        "        return False\n",
        "\n",
        "nifti_files = glob.glob(nifti_file_path)\n",
        "nifti_files = [f for f in nifti_files if is_valid_nifti(f)]\n",
        "\n",
        "print(\"NIfTI files found:\", nifti_files)\n",
        "\n",
        "# Run the pipeline\n",
        "fmri_features = process_nifti_files(nifti_files, save_dir, process_dir)\n",
        "\n",
        "print(\"Preprocessing complete!\")\n"
      ],
      "metadata": {
        "id": "N79JpJbbZyl4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3629fcdd-3711-49d5-ca40-f59bf70885bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NIfTI files found: ['/content/extracted_data/COBRE/sub-A00014590/ses-20110101/func/sub-A00014590_ses-20110101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00037224/ses-20130101/func/sub-A00037224_ses-20130101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00029486/ses-20120101/func/sub-A00029486_ses-20120101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00015518/ses-20100101/func/sub-A00015518_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00016197/ses-20090101/func/sub-A00016197_ses-20090101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00027119/ses-20100101/func/sub-A00027119_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00000838/ses-20100101/func/sub-A00000838_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00000541/ses-20110101/func/sub-A00000541_ses-20110101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00000541/ses-20100101/func/sub-A00000541_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00001243/ses-20110101/func/sub-A00001243_ses-20110101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00035836/ses-20130101/func/sub-A00035836_ses-20130101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00028805/ses-20120101/func/sub-A00028805_ses-20120101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00000909/ses-20110101/func/sub-A00000909_ses-20110101_task-rest_run-01_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00000909/ses-20110101/func/sub-A00000909_ses-20110101_task-rest_run-02_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00038441/ses-20130101/func/sub-A00038441_ses-20130101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00024228/ses-20090101/func/sub-A00024228_ses-20090101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00001251/ses-20110101/func/sub-A00001251_ses-20110101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00037619/ses-20130101/func/sub-A00037619_ses-20130101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00027410/ses-20120101/func/sub-A00027410_ses-20120101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00020416/ses-20110101/func/sub-A00020416_ses-20110101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00020416/ses-20100101/func/sub-A00020416_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00002480/ses-20110101/func/sub-A00002480_ses-20110101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00018598/ses-20100101/func/sub-A00018598_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00037034/ses-20130101/func/sub-A00037034_ses-20130101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00031271/ses-20120101/func/sub-A00031271_ses-20120101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00014719/ses-20120101/func/sub-A00014719_ses-20120101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00018317/ses-20100101/func/sub-A00018317_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00014636/ses-20090101/func/sub-A00014636_ses-20090101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00038624/ses-20130101/func/sub-A00038624_ses-20130101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00035485/ses-20120101/func/sub-A00035485_ses-20120101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00023590/ses-20100101/func/sub-A00023590_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00034273/ses-20120101/func/sub-A00034273_ses-20120101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00028303/ses-20120101/func/sub-A00028303_ses-20120101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00019293/ses-20100101/func/sub-A00019293_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00014830/ses-20090101/func/sub-A00014830_ses-20090101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00024953/ses-20090101/func/sub-A00024953_ses-20090101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00023246/ses-20110101/func/sub-A00023246_ses-20110101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00027391/ses-20110101/func/sub-A00027391_ses-20110101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00028405/ses-20120101/func/sub-A00028405_ses-20120101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00024198/ses-20090101/func/sub-A00024198_ses-20090101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00027537/ses-20110101/func/sub-A00027537_ses-20110101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00015648/ses-20110101/func/sub-A00015648_ses-20110101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00004507/ses-20120101/func/sub-A00004507_ses-20120101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00012767/ses-20100101/func/sub-A00012767_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00018979/ses-20110101/func/sub-A00018979_ses-20110101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00018979/ses-20100101/func/sub-A00018979_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00014607/ses-20100101/func/sub-A00014607_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00037649/ses-20130101/func/sub-A00037649_ses-20130101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00022500/ses-20100101/func/sub-A00022500_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00023750/ses-20090101/func/sub-A00023750_ses-20090101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00028408/ses-20120101/func/sub-A00028408_ses-20120101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00009280/ses-20110101/func/sub-A00009280_ses-20110101_task-rest_run-01_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00009280/ses-20110101/func/sub-A00009280_ses-20110101_task-rest_run-02_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00009656/ses-20110101/func/sub-A00009656_ses-20110101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00038172/ses-20130101/func/sub-A00038172_ses-20130101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00035003/ses-20120101/func/sub-A00035003_ses-20120101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00019349/ses-20100101/func/sub-A00019349_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00027969/ses-20110101/func/sub-A00027969_ses-20110101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00015201/ses-20110101/func/sub-A00015201_ses-20110101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00028404/ses-20110101/func/sub-A00028404_ses-20110101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00023243/ses-20090101/func/sub-A00023243_ses-20090101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00001452/ses-20100101/func/sub-A00001452_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00028189/ses-20120101/func/sub-A00028189_ses-20120101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00016723/ses-20100101/func/sub-A00016723_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00021591/ses-20110101/func/sub-A00021591_ses-20110101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00020602/ses-20110101/func/sub-A00020602_ses-20110101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00020602/ses-20100101/func/sub-A00020602_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00020414/ses-20100101/func/sub-A00020414_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00014804/ses-20090101/func/sub-A00014804_ses-20090101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00027755/ses-20110101/func/sub-A00027755_ses-20110101_task-rest_run-02_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00027755/ses-20110101/func/sub-A00027755_ses-20110101_task-rest_run-01_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00000368/ses-20110101/func/sub-A00000368_ses-20110101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00020787/ses-20100101/func/sub-A00020787_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00024510/ses-20090101/func/sub-A00024510_ses-20090101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00017147/ses-20110101/func/sub-A00017147_ses-20110101_task-rest_run-01_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00017147/ses-20110101/func/sub-A00017147_ses-20110101_task-rest_run-02_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00037854/ses-20130101/func/sub-A00037854_ses-20130101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00019750/ses-20120101/func/sub-A00019750_ses-20120101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00016720/ses-20110101/func/sub-A00016720_ses-20110101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00016720/ses-20100101/func/sub-A00016720_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00014175/ses-20110101/func/sub-A00014175_ses-20110101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00018403/ses-20110101/func/sub-A00018403_ses-20110101_task-rest_run-02_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00018403/ses-20110101/func/sub-A00018403_ses-20110101_task-rest_run-01_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00031597/ses-20120101/func/sub-A00031597_ses-20120101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00000456/ses-20090101/func/sub-A00000456_ses-20090101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00018129/ses-20110101/func/sub-A00018129_ses-20110101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00018129/ses-20100101/func/sub-A00018129_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00006754/ses-20110101/func/sub-A00006754_ses-20110101_task-rest_run-02_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00006754/ses-20110101/func/sub-A00006754_ses-20110101_task-rest_run-01_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00013216/ses-20110101/func/sub-A00013216_ses-20110101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00018434/ses-20100101/func/sub-A00018434_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00031186/ses-20120101/func/sub-A00031186_ses-20120101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00035859/ses-20120101/func/sub-A00035859_ses-20120101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00028806/ses-20120101/func/sub-A00028806_ses-20120101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00001181/ses-20100101/func/sub-A00001181_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00028402/ses-20120101/func/sub-A00028402_ses-20120101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00021598/ses-20110101/func/sub-A00021598_ses-20110101_task-rest_run-02_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00021598/ses-20110101/func/sub-A00021598_ses-20110101_task-rest_run-01_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00024568/ses-20090101/func/sub-A00024568_ses-20090101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00024684/ses-20100101/func/sub-A00024684_ses-20100101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00023158/ses-20090101/func/sub-A00023158_ses-20090101_task-rest_bold.nii.gz', '/content/extracted_data/COBRE/sub-A00024959/ses-20090101/func/sub-A00024959_ses-20090101_task-rest_bold.nii.gz']\n",
            "Processing file 1/102: /content/extracted_data/COBRE/sub-A00014590/ses-20110101/func/sub-A00014590_ses-20110101_task-rest_bold.nii.gz\n",
            "(64, 64, 33, 150)\n",
            "(64, 64, 33, 150)\n",
            "135168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/nilearn/decomposition/_base.py:492: UserWarning: memory_level is currently set to 0 but a Memory object has been provided. Setting memory_level to 1.\n",
            "  self.masker_.fit()\n",
            "/usr/local/lib/python3.11/dist-packages/nilearn/decomposition/canica.py:292: UserWarning: memory_level is currently set to 0 but a Memory object has been provided. Setting memory_level to 1.\n",
            "  components = _MultiPCA._raw_fit(self, data)\n",
            "<ipython-input-6-0752c35b9a67>:115: FutureWarning: The nifti_maps_masker_ attribute is deprecated andwill be removed in Nilearn 0.11.3. Please use maps_masker_ instead.\n",
            "  ica.fit(smoothed_img)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 490)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 443)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 468)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 472)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 513)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 448)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 517)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 498)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 498)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 439)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 500)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 485)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 470)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 912)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 477)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 461)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 455)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 454)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 417)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 462)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 453)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 505)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 465)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 467)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 520)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 506)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 489)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 454)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 477)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 569)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 397)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 336)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 1098)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 451)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 479)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 425)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 495)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 524)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 477)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 451)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 531)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 464)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 416)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 423)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 525)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 511)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 506)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 579)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 1075)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 99)\n",
            "Processing file 2/102: /content/extracted_data/COBRE/sub-A00037224/ses-20130101/func/sub-A00037224_ses-20130101_task-rest_bold.nii.gz\n",
            "(64, 64, 33, 150)\n",
            "(64, 64, 33, 150)\n",
            "135168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/nilearn/decomposition/_base.py:492: UserWarning: memory_level is currently set to 0 but a Memory object has been provided. Setting memory_level to 1.\n",
            "  self.masker_.fit()\n",
            "/usr/local/lib/python3.11/dist-packages/nilearn/decomposition/canica.py:292: UserWarning: memory_level is currently set to 0 but a Memory object has been provided. Setting memory_level to 1.\n",
            "  components = _MultiPCA._raw_fit(self, data)\n",
            "<ipython-input-6-0752c35b9a67>:115: FutureWarning: The nifti_maps_masker_ attribute is deprecated andwill be removed in Nilearn 0.11.3. Please use maps_masker_ instead.\n",
            "  ica.fit(smoothed_img)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 491)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 793)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 418)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 532)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 327)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 428)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 456)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 428)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 493)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 467)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 448)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 462)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 438)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 473)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 419)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 781)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 518)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 1055)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 441)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 479)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 511)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 484)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 438)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 443)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 804)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 430)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 496)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 471)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 422)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 446)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 464)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 426)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 515)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 358)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 460)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 437)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 507)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 447)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 456)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 594)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 397)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 489)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 448)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 465)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 216)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 489)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 454)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 555)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 445)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 445)\n",
            "Processing file 3/102: /content/extracted_data/COBRE/sub-A00029486/ses-20120101/func/sub-A00029486_ses-20120101_task-rest_bold.nii.gz\n",
            "(64, 64, 33, 150)\n",
            "(64, 64, 33, 150)\n",
            "135168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/nilearn/decomposition/_base.py:492: UserWarning: memory_level is currently set to 0 but a Memory object has been provided. Setting memory_level to 1.\n",
            "  self.masker_.fit()\n",
            "/usr/local/lib/python3.11/dist-packages/nilearn/decomposition/canica.py:292: UserWarning: memory_level is currently set to 0 but a Memory object has been provided. Setting memory_level to 1.\n",
            "  components = _MultiPCA._raw_fit(self, data)\n",
            "<ipython-input-6-0752c35b9a67>:115: FutureWarning: The nifti_maps_masker_ attribute is deprecated andwill be removed in Nilearn 0.11.3. Please use maps_masker_ instead.\n",
            "  ica.fit(smoothed_img)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 479)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 534)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 556)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 563)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 435)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 540)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 570)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 471)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 478)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 464)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 524)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 342)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 481)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 473)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 91)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 496)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 525)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 470)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 436)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 497)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 517)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 536)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 554)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 556)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 537)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 509)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 1054)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 462)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 527)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 509)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 489)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 474)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 508)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 511)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 622)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 458)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 118)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 502)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 331)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 485)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 934)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 474)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 528)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 433)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 529)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 470)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 519)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 574)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 496)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 544)\n",
            "Processing file 4/102: /content/extracted_data/COBRE/sub-A00015518/ses-20100101/func/sub-A00015518_ses-20100101_task-rest_bold.nii.gz\n",
            "(64, 64, 33, 150)\n",
            "(64, 64, 33, 150)\n",
            "135168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/nilearn/decomposition/_base.py:492: UserWarning: memory_level is currently set to 0 but a Memory object has been provided. Setting memory_level to 1.\n",
            "  self.masker_.fit()\n",
            "/usr/local/lib/python3.11/dist-packages/nilearn/decomposition/canica.py:292: UserWarning: memory_level is currently set to 0 but a Memory object has been provided. Setting memory_level to 1.\n",
            "  components = _MultiPCA._raw_fit(self, data)\n",
            "<ipython-input-6-0752c35b9a67>:115: FutureWarning: The nifti_maps_masker_ attribute is deprecated andwill be removed in Nilearn 0.11.3. Please use maps_masker_ instead.\n",
            "  ica.fit(smoothed_img)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 555)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 467)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 486)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 490)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 467)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 537)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 510)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 501)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 479)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 462)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 513)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 502)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 536)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 537)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 523)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 484)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 469)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 476)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 384)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 164)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 452)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 532)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 228)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 515)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 537)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 484)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 448)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 489)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 291)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 505)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 485)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 470)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 467)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 503)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 505)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 537)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 517)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 583)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 525)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 485)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 485)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 465)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 510)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 237)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 497)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 471)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 493)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 521)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 506)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 457)\n",
            "Processing file 5/102: /content/extracted_data/COBRE/sub-A00016197/ses-20090101/func/sub-A00016197_ses-20090101_task-rest_bold.nii.gz\n",
            "(64, 64, 33, 150)\n",
            "(64, 64, 33, 150)\n",
            "135168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/nilearn/decomposition/_base.py:492: UserWarning: memory_level is currently set to 0 but a Memory object has been provided. Setting memory_level to 1.\n",
            "  self.masker_.fit()\n",
            "/usr/local/lib/python3.11/dist-packages/nilearn/decomposition/canica.py:292: UserWarning: memory_level is currently set to 0 but a Memory object has been provided. Setting memory_level to 1.\n",
            "  components = _MultiPCA._raw_fit(self, data)\n",
            "<ipython-input-6-0752c35b9a67>:115: FutureWarning: The nifti_maps_masker_ attribute is deprecated andwill be removed in Nilearn 0.11.3. Please use maps_masker_ instead.\n",
            "  ica.fit(smoothed_img)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 401)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 398)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 149)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 383)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 364)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 411)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 371)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 368)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 382)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 361)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 379)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 378)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 381)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 382)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 718)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 364)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 366)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 408)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 376)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 430)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 416)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 382)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 395)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 372)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 407)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 342)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 397)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 418)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 405)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 379)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 143)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 389)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 375)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 372)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 389)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 329)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 375)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 406)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 383)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 350)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 378)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 373)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 379)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 346)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 379)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 371)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 411)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 393)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 361)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 416)\n",
            "Processing file 6/102: /content/extracted_data/COBRE/sub-A00027119/ses-20100101/func/sub-A00027119_ses-20100101_task-rest_bold.nii.gz\n",
            "(64, 64, 33, 150)\n",
            "(64, 64, 33, 150)\n",
            "135168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/nilearn/decomposition/_base.py:492: UserWarning: memory_level is currently set to 0 but a Memory object has been provided. Setting memory_level to 1.\n",
            "  self.masker_.fit()\n",
            "/usr/local/lib/python3.11/dist-packages/nilearn/decomposition/canica.py:292: UserWarning: memory_level is currently set to 0 but a Memory object has been provided. Setting memory_level to 1.\n",
            "  components = _MultiPCA._raw_fit(self, data)\n",
            "<ipython-input-6-0752c35b9a67>:115: FutureWarning: The nifti_maps_masker_ attribute is deprecated andwill be removed in Nilearn 0.11.3. Please use maps_masker_ instead.\n",
            "  ica.fit(smoothed_img)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 507)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 522)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 517)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 556)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 497)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 468)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 481)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 529)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 556)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 529)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 547)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 496)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 507)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 485)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 440)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 567)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 518)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 496)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 519)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 621)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 706)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 391)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 431)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 105)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 512)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 552)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 512)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 540)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 547)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 396)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 500)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 594)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 482)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 289)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 577)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 463)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 390)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 505)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 559)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 634)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 509)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 438)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 536)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 505)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 413)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 536)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 444)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 581)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 498)\n",
            "Checking masker...\n",
            "Checking smoothed image...\n",
            "Applying masker transformation...\n",
            "Time series data shape: (150, 510)\n",
            "Preprocessing complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(fmri_features.shape)"
      ],
      "metadata": {
        "id": "LPw4AYr0HgAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "# Define paths\n",
        "uploaded_file_path = '/content/drive/MyDrive/dataverse_files.zip'\n",
        "data_dir = '/content/extracted_eeg_data'\n",
        "os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "# Extract the contents of the zip file\n",
        "with zipfile.ZipFile(uploaded_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(data_dir)\n",
        "print(\"Google Drive mounted and paths defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbzvjzbS56Wp",
        "outputId": "ab7bf612-ab02-4247-b0f9-c4d7b3248cc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive mounted and paths defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import mne\n",
        "from mne.io import read_raw_edf\n",
        "from mne.channels import make_standard_montage\n",
        "\n",
        "# Constants\n",
        "DATA_DIR = \"/path/to/edf/files\"  # Update this\n",
        "OUTPUT_DIR = \"/path/to/eeg_features\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Define electrode groups for brain regions (simplified)\n",
        "REGIONS = {\n",
        "    \"frontal\": [\"Fp1\", \"Fp2\", \"F3\", \"F4\", \"F7\", \"F8\"],\n",
        "    \"central\": [\"C3\", \"C4\", \"Cz\"],\n",
        "    \"temporal\": [\"T3\", \"T4\", \"T5\", \"T6\"],\n",
        "    \"parietal\": [\"P3\", \"P4\", \"Pz\"],\n",
        "    \"occipital\": [\"O1\", \"O2\"]\n",
        "}\n",
        "\n",
        "BANDS = {\n",
        "    \"delta\": (0.5, 4),\n",
        "    \"theta\": (4, 8),\n",
        "    \"alpha\": (8, 12),\n",
        "    \"beta\": (12, 30)\n",
        "}\n",
        "\n",
        "def extract_eeg_features(raw, label):\n",
        "    \"\"\"Extract region-specific spectral power (mean + std) per subject.\"\"\"\n",
        "    # Preprocess\n",
        "    raw.pick_types(eeg=True)\n",
        "    raw.set_montage(make_standard_montage(\"standard_1020\"))  # Ensure electrode positions\n",
        "    raw.filter(0.5, 30., fir_design='firwin')  # Skip gamma (noisy in EEG)\n",
        "\n",
        "    # Extract epochs (non-overlapping 2s windows)\n",
        "    epochs = mne.make_fixed_length_epochs(raw, duration=2, preload=True)\n",
        "\n",
        "    # Compute PSD for all epochs\n",
        "    psds, freqs = mne.time_frequency.psd_array_welch(\n",
        "        epochs.get_data(),\n",
        "        sfreq=raw.info[\"sfreq\"],\n",
        "        fmin=0.5,\n",
        "        fmax=30,\n",
        "        n_fft=256\n",
        "    )\n",
        "\n",
        "    # Aggregate features per region and band\n",
        "    features = []\n",
        "    for region, channels in REGIONS.items():\n",
        "        # Find indices of channels in the region\n",
        "        chan_indices = [i for i, ch in enumerate(raw.ch_names) if ch in channels]\n",
        "        if not chan_indices:\n",
        "            continue  # Skip if no channels found\n",
        "\n",
        "        for band, (fmin, fmax) in BANDS.items():\n",
        "            # Compute mean power across epochs and channels in the region\n",
        "            band_mask = (freqs >= fmin) & (freqs < fmax)\n",
        "            band_power = psds[:, chan_indices, :][..., band_mask].mean(axis=(0, 1, 3))\n",
        "            band_std = psds[:, chan_indices, :][..., band_mask].std(axis=(0, 1, 3))\n",
        "\n",
        "            features.extend([band_power, band_std])\n",
        "\n",
        "    # Add label and save (one file per subject)\n",
        "    features.append(label)\n",
        "    output_file = os.path.join(OUTPUT_DIR, f\"{os.path.splitext(file_name)[0]}_features.npy\")\n",
        "    np.save(output_file, np.array(features))\n",
        "\n",
        "# Process files\n",
        "for file_name in os.listdir(DATA_DIR):\n",
        "    if file_name.endswith(\".edf\"):\n",
        "        file_path = os.path.join(DATA_DIR, file_name)\n",
        "        try:\n",
        "            raw = read_raw_edf(file_path, preload=True)\n",
        "            label = 0 if file_name.startswith(\"h\") else 1  # Update label logic\n",
        "            extract_eeg_features(raw, label)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {file_name}: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9BT3nNUOnti",
        "outputId": "742977d1-0d09-4204-eedd-80658c6260dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mne\n",
            "  Downloading mne-1.9.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mne) (3.1.5)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.11/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from mne) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mne) (24.2)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.11/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from mne) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (2.32.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6->mne) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.1.31)\n",
            "Downloading mne-1.9.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mne\n",
            "Successfully installed mne-1.9.0\n",
            "Processing file: /content/extracted_eeg_data/h10.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/h10.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 278749  =      0.000 ...  1114.996 secs...\n",
            "Assigned label 0 for file h10.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "558 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 558 events and 501 original time points ...\n",
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (557, 95), Label: 0, Final shape: (557, 96)\n",
            "Saved features to /content/eeg_features/h10_features.npy\n",
            "Processing file: /content/extracted_eeg_data/h03.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/h03.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 227499  =      0.000 ...   909.996 secs...\n",
            "Assigned label 0 for file h03.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "455 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 455 events and 501 original time points ...\n",
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (454, 95), Label: 0, Final shape: (454, 96)\n",
            "Saved features to /content/eeg_features/h03_features.npy\n",
            "Processing file: /content/extracted_eeg_data/h12.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/h12.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 224999  =      0.000 ...   899.996 secs...\n",
            "Assigned label 0 for file h12.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "450 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 450 events and 501 original time points ...\n",
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (449, 95), Label: 0, Final shape: (449, 96)\n",
            "Saved features to /content/eeg_features/h12_features.npy\n",
            "Processing file: /content/extracted_eeg_data/s02.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/s02.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 286249  =      0.000 ...  1144.996 secs...\n",
            "Assigned label 1 for file s02.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "573 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 573 events and 501 original time points ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n",
            "Shape of features: (572, 95), Label: 1, Final shape: (572, 96)\n",
            "Saved features to /content/eeg_features/s02_features.npy\n",
            "Processing file: /content/extracted_eeg_data/s06.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/s06.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 184999  =      0.000 ...   739.996 secs...\n",
            "Assigned label 1 for file s06.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "370 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 370 events and 501 original time points ...\n",
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (369, 95), Label: 1, Final shape: (369, 96)\n",
            "Saved features to /content/eeg_features/s06_features.npy\n",
            "Processing file: /content/extracted_eeg_data/h02.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/h02.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 227499  =      0.000 ...   909.996 secs...\n",
            "Assigned label 0 for file h02.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "455 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 455 events and 501 original time points ...\n",
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (454, 95), Label: 0, Final shape: (454, 96)\n",
            "Saved features to /content/eeg_features/h02_features.npy\n",
            "Processing file: /content/extracted_eeg_data/s01.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/s01.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 211249  =      0.000 ...   844.996 secs...\n",
            "Assigned label 1 for file s01.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "423 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 423 events and 501 original time points ...\n",
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (422, 95), Label: 1, Final shape: (422, 96)\n",
            "Saved features to /content/eeg_features/s01_features.npy\n",
            "Processing file: /content/extracted_eeg_data/h08.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/h08.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 227499  =      0.000 ...   909.996 secs...\n",
            "Assigned label 0 for file h08.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "455 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 455 events and 501 original time points ...\n",
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (454, 95), Label: 0, Final shape: (454, 96)\n",
            "Saved features to /content/eeg_features/h08_features.npy\n",
            "Processing file: /content/extracted_eeg_data/s10.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/s10.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 212499  =      0.000 ...   849.996 secs...\n",
            "Assigned label 1 for file s10.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "425 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 425 events and 501 original time points ...\n",
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (424, 95), Label: 1, Final shape: (424, 96)\n",
            "Saved features to /content/eeg_features/s10_features.npy\n",
            "Processing file: /content/extracted_eeg_data/s07.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/s07.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 336499  =      0.000 ...  1345.996 secs...\n",
            "Assigned label 1 for file s07.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "673 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 673 events and 501 original time points ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n",
            "Shape of features: (672, 95), Label: 1, Final shape: (672, 96)\n",
            "Saved features to /content/eeg_features/s07_features.npy\n",
            "Processing file: /content/extracted_eeg_data/s11.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/s11.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 339999  =      0.000 ...  1359.996 secs...\n",
            "Assigned label 1 for file s11.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "680 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 680 events and 501 original time points ...\n",
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (679, 95), Label: 1, Final shape: (679, 96)\n",
            "Saved features to /content/eeg_features/s11_features.npy\n",
            "Processing file: /content/extracted_eeg_data/h14.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/h14.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 216249  =      0.000 ...   864.996 secs...\n",
            "Assigned label 0 for file h14.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "433 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 433 events and 501 original time points ...\n",
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (432, 95), Label: 0, Final shape: (432, 96)\n",
            "Saved features to /content/eeg_features/h14_features.npy\n",
            "Processing file: /content/extracted_eeg_data/h11.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/h11.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 228749  =      0.000 ...   914.996 secs...\n",
            "Assigned label 0 for file h11.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "458 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 458 events and 501 original time points ...\n",
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (457, 95), Label: 0, Final shape: (457, 96)\n",
            "Saved features to /content/eeg_features/h11_features.npy\n",
            "Processing file: /content/extracted_eeg_data/s09.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/s09.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 296249  =      0.000 ...  1184.996 secs...\n",
            "Assigned label 1 for file s09.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "593 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 593 events and 501 original time points ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n",
            "Shape of features: (592, 95), Label: 1, Final shape: (592, 96)\n",
            "Saved features to /content/eeg_features/s09_features.npy\n",
            "Processing file: /content/extracted_eeg_data/s13.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/s13.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 283749  =      0.000 ...  1134.996 secs...\n",
            "Assigned label 1 for file s13.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "568 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 568 events and 501 original time points ...\n",
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (567, 95), Label: 1, Final shape: (567, 96)\n",
            "Saved features to /content/eeg_features/s13_features.npy\n",
            "Processing file: /content/extracted_eeg_data/h01.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/h01.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 231249  =      0.000 ...   924.996 secs...\n",
            "Assigned label 0 for file h01.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "463 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 463 events and 501 original time points ...\n",
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (462, 95), Label: 0, Final shape: (462, 96)\n",
            "Saved features to /content/eeg_features/h01_features.npy\n",
            "Processing file: /content/extracted_eeg_data/s03.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/s03.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 240999  =      0.000 ...   963.996 secs...\n",
            "Assigned label 1 for file s03.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "482 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 482 events and 501 original time points ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n",
            "Shape of features: (481, 95), Label: 1, Final shape: (481, 96)\n",
            "Saved features to /content/eeg_features/s03_features.npy\n",
            "Processing file: /content/extracted_eeg_data/h06.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/h06.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 232499  =      0.000 ...   929.996 secs...\n",
            "Assigned label 0 for file h06.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "465 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 465 events and 501 original time points ...\n",
            "1 bad epochs dropped\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Effective window size : 1.024 (s)\n",
            "Shape of features: (464, 95), Label: 0, Final shape: (464, 96)\n",
            "Saved features to /content/eeg_features/h06_features.npy\n",
            "Processing file: /content/extracted_eeg_data/h13.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/h13.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 241249  =      0.000 ...   964.996 secs...\n",
            "Assigned label 0 for file h13.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "483 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 483 events and 501 original time points ...\n",
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (482, 95), Label: 0, Final shape: (482, 96)\n",
            "Saved features to /content/eeg_features/h13_features.npy\n",
            "Processing file: /content/extracted_eeg_data/s05.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/s05.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 222499  =      0.000 ...   889.996 secs...\n",
            "Assigned label 1 for file s05.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "445 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 445 events and 501 original time points ...\n",
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (444, 95), Label: 1, Final shape: (444, 96)\n",
            "Saved features to /content/eeg_features/s05_features.npy\n",
            "Processing file: /content/extracted_eeg_data/h04.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/h04.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 231249  =      0.000 ...   924.996 secs...\n",
            "Assigned label 0 for file h04.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "463 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 463 events and 501 original time points ...\n",
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (462, 95), Label: 0, Final shape: (462, 96)\n",
            "Saved features to /content/eeg_features/h04_features.npy\n",
            "Processing file: /content/extracted_eeg_data/s04.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/s04.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 301249  =      0.000 ...  1204.996 secs...\n",
            "Assigned label 1 for file s04.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "603 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 603 events and 501 original time points ...\n",
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (602, 95), Label: 1, Final shape: (602, 96)\n",
            "Saved features to /content/eeg_features/s04_features.npy\n",
            "Processing file: /content/extracted_eeg_data/h05.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/h05.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 236249  =      0.000 ...   944.996 secs...\n",
            "Assigned label 0 for file h05.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "473 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 473 events and 501 original time points ...\n",
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (472, 95), Label: 0, Final shape: (472, 96)\n",
            "Saved features to /content/eeg_features/h05_features.npy\n",
            "Processing file: /content/extracted_eeg_data/s12.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/s12.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 271749  =      0.000 ...  1086.996 secs...\n",
            "Assigned label 1 for file s12.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "544 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 544 events and 501 original time points ...\n",
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (543, 95), Label: 1, Final shape: (543, 96)\n",
            "Saved features to /content/eeg_features/s12_features.npy\n",
            "Processing file: /content/extracted_eeg_data/s14.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/s14.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 542499  =      0.000 ...  2169.996 secs...\n",
            "Assigned label 1 for file s14.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "1085 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 1085 events and 501 original time points ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n",
            "Shape of features: (1084, 95), Label: 1, Final shape: (1084, 96)\n",
            "Saved features to /content/eeg_features/s14_features.npy\n",
            "Processing file: /content/extracted_eeg_data/s08.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/s08.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 227749  =      0.000 ...   910.996 secs...\n",
            "Assigned label 1 for file s08.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "456 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 456 events and 501 original time points ...\n",
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (455, 95), Label: 1, Final shape: (455, 96)\n",
            "Saved features to /content/eeg_features/s08_features.npy\n",
            "Processing file: /content/extracted_eeg_data/h07.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/h07.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 227499  =      0.000 ...   909.996 secs...\n",
            "Assigned label 0 for file h07.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "455 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 455 events and 501 original time points ...\n",
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (454, 95), Label: 0, Final shape: (454, 96)\n",
            "Saved features to /content/eeg_features/h07_features.npy\n",
            "Processing file: /content/extracted_eeg_data/h09.edf\n",
            "Extracting EDF parameters from /content/extracted_eeg_data/h09.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 226249  =      0.000 ...   904.996 secs...\n",
            "Assigned label 0 for file h09.edf\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 1651 samples (6.604 s)\n",
            "\n",
            "Not setting metadata\n",
            "453 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 453 events and 501 original time points ...\n",
            "1 bad epochs dropped\n",
            "Effective window size : 1.024 (s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (452, 95), Label: 0, Final shape: (452, 96)\n",
            "Saved features to /content/eeg_features/h09_features.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "def load_eeg_features(data_dir):\n",
        "    \"\"\"\n",
        "    Load EEG features aggregated per subject\n",
        "    Returns:\n",
        "        eeg_features: np.array of shape [n_subjects, n_features]\n",
        "        eeg_labels: np.array of shape [n_subjects]\n",
        "    \"\"\"\n",
        "    subject_features = []\n",
        "    subject_labels = []\n",
        "\n",
        "    # Validate directory\n",
        "    if not os.path.isdir(data_dir):\n",
        "        raise ValueError(f\"Invalid data directory: {data_dir}\")\n",
        "\n",
        "    # Load and process each file\n",
        "    for file_name in sorted(os.listdir(data_dir)):\n",
        "        if file_name.endswith(\"_features.npy\"):\n",
        "            try:\n",
        "                file_path = os.path.join(data_dir, file_name)\n",
        "\n",
        "                # Load data\n",
        "                data = np.load(file_path)\n",
        "\n",
        "                # Validate data shape\n",
        "                if data.ndim != 2 or data.shape[1] < 2:\n",
        "                    raise ValueError(f\"Invalid shape {data.shape} in {file_name}\")\n",
        "\n",
        "                # Separate features and labels\n",
        "                features = data[:, :-1]  # All columns except last\n",
        "                labels = data[:, -1]     # Last column as labels\n",
        "\n",
        "                # Verify consistent labels per subject\n",
        "                unique_labels = np.unique(labels)\n",
        "                if len(unique_labels) != 1:\n",
        "                    raise ValueError(f\"Multiple labels found in {file_name}\")\n",
        "\n",
        "                # Average across epochs (assuming rows=epochs)\n",
        "                subject_features.append(np.mean(features, axis=0))\n",
        "                subject_labels.append(unique_labels[0])\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Skipping {file_name} due to error: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    eeg_features = np.array(subject_features)\n",
        "    eeg_labels = np.array(subject_labels)\n",
        "\n",
        "    # Final validation\n",
        "    if len(eeg_features) == 0:\n",
        "        raise ValueError(\"No valid EEG data found\")\n",
        "\n",
        "    if eeg_features.shape[0] != eeg_labels.shape[0]:\n",
        "        raise ValueError(\"Feature/label count mismatch\")\n",
        "\n",
        "    print(f\"Loaded {len(eeg_features)} subjects with {eeg_features.shape[1]} features\")\n",
        "    return eeg_features, eeg_labels\n",
        "\n",
        "# Usage example\n",
        "output_dir = \"/content/eeg_features/\"\n",
        "eeg_features, eeg_labels = load_eeg_features(output_dir)\n",
        "\n",
        "print(\"EEG features shape:\", eeg_features.shape)  # [n_subjects, n_features]\n",
        "print(\"Labels shape:\", eeg_labels.shape)         # [n_subjects]"
      ],
      "metadata": {
        "id": "ubIxXVQtK-7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "\n",
        "# =====================\n",
        "# 1. Data Preparation\n",
        "# =====================\n",
        "\n",
        "class DomainAdaptationDataset(Dataset):\n",
        "    def __init__(self, source_features, source_labels, target_features):\n",
        "        self.source_features = source_features\n",
        "        self.source_labels = source_labels\n",
        "        self.target_features = target_features\n",
        "\n",
        "    def __len__(self):\n",
        "        return max(len(self.source_features), len(self.target_features))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        source_idx = idx % len(self.source_features)\n",
        "        target_idx = idx % len(self.target_features)\n",
        "\n",
        "        return {\n",
        "            'source': (self.source_features[source_idx], self.source_labels[source_idx]),\n",
        "            'target': (self.target_features[target_idx], -1)  # Dummy label\n",
        "        }\n",
        "\n",
        "# =====================\n",
        "# 2. DANN Architecture\n",
        "# =====================\n",
        "\n",
        "class GradientReversalLayer(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, alpha):\n",
        "        ctx.alpha = alpha\n",
        "        return x.view_as(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        return grad_output.neg() * ctx.alpha, None\n",
        "\n",
        "class DANN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=64):\n",
        "        super(DANN, self).__init__()\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.task_classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.domain_classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x, alpha=1.0):\n",
        "        features = self.feature_extractor(x)\n",
        "        task_output = self.task_classifier(features)\n",
        "        reversed_features = GradientReversalLayer.apply(features, alpha)\n",
        "        domain_output = self.domain_classifier(reversed_features)\n",
        "        return task_output, domain_output\n",
        "\n",
        "# =====================\n",
        "# 3. Training Loop with Validation\n",
        "# =====================\n",
        "\n",
        "def train_dann(eeg_train, labels_train, fmri_features, eeg_val, labels_val, num_epochs=100, lambda_val=0.1):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Standardize features\n",
        "    scaler = StandardScaler()\n",
        "    combined = np.vstack([eeg_train, fmri_features])\n",
        "    scaler.fit(combined)\n",
        "\n",
        "    eeg_train_scaled = scaler.transform(eeg_train)\n",
        "    eeg_val_scaled = scaler.transform(eeg_val)\n",
        "    fmri_scaled = scaler.transform(fmri_features)\n",
        "\n",
        "    # Create dataset and dataloader\n",
        "    dataset = DomainAdaptationDataset(\n",
        "        source_features=eeg_train_scaled,\n",
        "        source_labels=labels_train,\n",
        "        target_features=fmri_scaled\n",
        "    )\n",
        "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "    # Initialize model\n",
        "    model = DANN(input_dim=eeg_train_scaled.shape[1]).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "    task_loss_fn = nn.BCELoss()\n",
        "    domain_loss_fn = nn.BCELoss()\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "    best_model_state = None\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_task_loss = 0\n",
        "        total_domain_loss = 0\n",
        "\n",
        "        for batch in dataloader:\n",
        "            # Training loop\n",
        "            source_data, source_labels = batch['source']\n",
        "            target_data, _ = batch['target']\n",
        "\n",
        "            source_data = source_data.float().to(device)\n",
        "            source_labels = source_labels.float().to(device)\n",
        "            target_data = target_data.float().to(device)\n",
        "\n",
        "            combined_data = torch.cat([source_data, target_data], dim=0)\n",
        "            batch_size = source_data.size(0)\n",
        "\n",
        "            domain_labels = torch.cat([\n",
        "                torch.zeros(batch_size),\n",
        "                torch.ones(combined_data.size(0) - batch_size)\n",
        "            ]).to(device)\n",
        "\n",
        "            task_preds, domain_preds = model(combined_data)\n",
        "            source_task_preds = task_preds[:batch_size]\n",
        "\n",
        "            task_loss = task_loss_fn(source_task_preds.squeeze(), source_labels)\n",
        "            domain_loss = domain_loss_fn(domain_preds.squeeze(), domain_labels)\n",
        "            total_loss = task_loss + lambda_val * domain_loss\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            total_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_task_loss += task_loss.item()\n",
        "            total_domain_loss += domain_loss.item()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_data = torch.tensor(eeg_val_scaled).float().to(device)\n",
        "            val_preds, _ = model(val_data)\n",
        "            val_preds = val_preds.squeeze().cpu().numpy().round()\n",
        "            val_acc = (val_preds == labels_val).mean()\n",
        "\n",
        "            if val_acc > best_val_acc:\n",
        "                best_val_acc = val_acc\n",
        "                best_model_state = model.state_dict()\n",
        "\n",
        "        print(f'Epoch {epoch+1}: Val Acc {val_acc:.2f}')\n",
        "\n",
        "    # Load best model\n",
        "    model.load_state_dict(best_model_state)\n",
        "    return model, scaler\n",
        "\n",
        "# =====================\n",
        "# 4. Evaluation Functions\n",
        "# =====================\n",
        "\n",
        "def evaluate_metrics(model, scaler, features, labels, name):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        scaled_features = scaler.transform(features)\n",
        "        features_tensor = torch.tensor(scaled_features).float().to(device)\n",
        "        predictions, _ = model(features_tensor)\n",
        "        preds = predictions.squeeze().cpu().numpy().round()\n",
        "\n",
        "    acc = (preds == labels).mean()\n",
        "    cm = confusion_matrix(labels, preds)\n",
        "    report = classification_report(labels, preds, zero_division=0)\n",
        "\n",
        "    print(f\"\\n{name} Evaluation:\")\n",
        "    print(f\"Accuracy: {acc*100:.2f}%\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(report)\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    return acc, cm, report\n",
        "\n",
        "# =====================\n",
        "# 5. Cross-Validation Pipeline\n",
        "# =====================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Load data\n",
        "    eeg_features = np.load('/path/to/eeg_features.npy')\n",
        "    eeg_labels = np.load('/path/to/eeg_labels.npy')\n",
        "    fmri_features = np.load('/path/to/fmri_features.npy')\n",
        "    fmri_labels = np.ones(len(fmri_features))\n",
        "\n",
        "    # Initialize CV\n",
        "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for fold_idx, (train_val_idx, test_idx) in enumerate(kf.split(eeg_features, eeg_labels)):\n",
        "        print(f\"\\n=== Fold {fold_idx+1} ===\")\n",
        "\n",
        "        # Split into train/val/test\n",
        "        eeg_train_val = eeg_features[train_val_idx]\n",
        "        labels_train_val = eeg_labels[train_val_idx]\n",
        "        eeg_test = eeg_features[test_idx]\n",
        "        labels_test = eeg_labels[test_idx]\n",
        "\n",
        "        # Further split train_val into train/val\n",
        "        eeg_train, eeg_val, labels_train, labels_val = train_test_split(\n",
        "            eeg_train_val, labels_train_val,\n",
        "            test_size=0.25,\n",
        "            stratify=labels_train_val,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        # Train model\n",
        "        model, scaler = train_dann(\n",
        "            eeg_train, labels_train,\n",
        "            fmri_features,\n",
        "            eeg_val, labels_val,\n",
        "            num_epochs=100,\n",
        "            lambda_val=0.1\n",
        "        )\n",
        "\n",
        "        # Evaluate\n",
        "        test_acc, test_cm, test_report = evaluate_metrics(model, scaler, eeg_test, labels_test, \"EEG Test\")\n",
        "        fmri_acc, fmri_cm, fmri_report = evaluate_metrics(model, scaler, fmri_features, fmri_labels, \"fMRI\")\n",
        "\n",
        "        results.append({\n",
        "            'fold': fold_idx+1,\n",
        "            'test_acc': test_acc,\n",
        "            'fmri_acc': fmri_acc,\n",
        "            'test_cm': test_cm,\n",
        "            'fmri_cm': fmri_cm\n",
        "        })\n",
        "\n",
        "    # Final report\n",
        "    print(\"\\n=== Final Results ===\")\n",
        "    print(f\"Mean EEG Test Accuracy: {np.mean([r['test_acc'] for r in results])*100:.2f}%\")\n",
        "    print(f\"Mean fMRI Accuracy: {np.mean([r['fmri_acc'] for r in results])*100:.2f}%\")\n",
        "    print(\"\\nAggregated EEG Test Confusion Matrix:\")\n",
        "    print(sum([r['test_cm'] for r in results]))\n",
        "    print(\"\\nAggregated fMRI Confusion Matrix:\")\n",
        "    print(sum([r['fmri_cm'] for r in results]))"
      ],
      "metadata": {
        "id": "HwZXdkUfKTkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# -------------------\n",
        "# Data Preprocessing\n",
        "# -------------------\n",
        "def pad_or_truncate(data, target_size):\n",
        "    \"\"\"Pads with zeros or truncates the dataset to match the required size.\"\"\"\n",
        "    current_size = data.shape[0]\n",
        "    if current_size < target_size:\n",
        "        pad_size = target_size - current_size\n",
        "        pad_shape = (pad_size,) + data.shape[1:]  # Keep feature dimensions unchanged\n",
        "        pad_values = np.zeros(pad_shape)  # Pad with zeros\n",
        "        return np.vstack((data, pad_values))  # Stack padded data\n",
        "    return data[:target_size]  # Truncate if larger\n",
        "\n",
        "# Reshape fMRI features\n",
        "fmri_features = fmri_features_old.reshape(fmri_features_old.shape[0], -1)\n",
        "\n",
        "# Align EEG and fMRI sample sizes\n",
        "num_samples = max(eeg_features.shape[0], fmri_features.shape[0])\n",
        "#X_eeg = pad_or_truncate(eeg_features, num_samples)\n",
        "X_fmri = pad_or_truncate(fmri_features, num_samples)\n",
        "y_target = pad_or_truncate(y.reshape(-1, 1), num_samples).flatten()\n",
        "\n",
        "pca = PCA(n_components=eeg_features.shape[1])\n",
        "fmri_aligned = pca.fit_transform(X_fmri)"
      ],
      "metadata": {
        "id": "QodDMoU7AY_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# -------------------\n",
        "# Data Preprocessing\n",
        "# -------------------\n",
        "def pad_or_truncate(data, target_size):\n",
        "    \"\"\"Pads with zeros or truncates the dataset to match the required size.\"\"\"\n",
        "    current_size = data.shape[0]\n",
        "    if current_size < target_size:\n",
        "        pad_size = target_size - current_size\n",
        "        pad_shape = (pad_size,) + data.shape[1:]  # Keep feature dimensions unchanged\n",
        "        pad_values = np.zeros(pad_shape)  # Pad with zeros\n",
        "        return np.vstack((data, pad_values))  # Stack padded data\n",
        "    return data[:target_size]  # Truncate if larger\n",
        "\n",
        "# Reshape fMRI features\n",
        "fmri_features = fmri_features_old.reshape(fmri_features_old.shape[0], -1)\n",
        "\n",
        "# Align EEG and fMRI sample sizes\n",
        "num_samples = max(eeg_features.shape[0], fmri_features.shape[0])\n",
        "#X_eeg = pad_or_truncate(eeg_features, num_samples)\n",
        "X_fmri = pad_or_truncate(fmri_features, num_samples)\n",
        "y_target = pad_or_truncate(y.reshape(-1, 1), num_samples).flatten()  # Ensure labels are 1D\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "# Combine EEG + fMRI\n",
        "\n",
        "pca = PCA(n_components=eeg_features.shape[1])\n",
        "fmri_aligned = pca.fit_transform(X_fmri)\n",
        "X_combined = np.hstack((eeg_features, fmri_aligned))\n",
        "# Standardize Data\n",
        "scaler = StandardScaler()\n",
        "X_combined = scaler.fit_transform(X_combined)\n",
        "\n",
        "# -------------------\n",
        "# Data Augmentation (Adding Noise)\n",
        "# -------------------\n",
        "def add_noise(data, noise_level=0.05):\n",
        "    noise = np.random.normal(0, noise_level, data.shape)\n",
        "    return data + noise\n",
        "\n",
        "# Augment Data\n",
        "X_noisy = add_noise(X_combined, noise_level=0.05)\n",
        "X_combined_augmented = np.vstack((X_combined, X_noisy))\n",
        "y_combined_augmented = np.hstack((y_target, y_target))\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_combined_augmented = torch.tensor(X_combined_augmented, dtype=torch.float32)\n",
        "y_combined_augmented = torch.tensor(y_combined_augmented, dtype=torch.float32)  # Float for BCE loss\n",
        "\n",
        "# Split into train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_combined_augmented, y_combined_augmented, test_size=0.25, random_state=42)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train, X_test = torch.tensor(X_train, dtype=torch.float32), torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train, y_test = torch.tensor(y_train, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=64, shuffle=False)\n",
        "\n",
        "# -------------------\n",
        "# Define Fusion Model\n",
        "# -------------------\n",
        "class FusionModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super(FusionModel, self).__init__()\n",
        "        '''self.conv = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=1, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2),\n",
        "            nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2),\n",
        "        )\n",
        "\n",
        "        conv_output_size = (input_dim // 4) * 128  # Adjust based on pooling layers\n",
        "'''\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(input_dim, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(1024, 1)  # 1 output for binary classification\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        #x = x.unsqueeze(1)  # (batch_size, 1, feature_dim) for Conv1D\n",
        "        #x = self.conv(x)\n",
        "        #x = x.view(x.shape[0], -1)  # Flatten\n",
        "        x = self.fc(x)\n",
        "        return x  # No sigmoid here, we use BCEWithLogitsLoss\n",
        "\n",
        "\n",
        "# Initialize the model\n",
        "model = FusionModel(input_dim=X_combined_augmented.shape[1], hidden_dim=1024)\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_target), y=y_target)\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
        "\n",
        "# Define Loss Function (with class weights)\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights[1])\n",
        "\n",
        "# Define Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Learning Rate Scheduler\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5, verbose=True)\n",
        "\n",
        "# -------------------\n",
        "# Training Loop\n",
        "# -------------------\n",
        "best_loss = float('inf')\n",
        "for epoch in range(50):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        inputs, labels = batch\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs).squeeze(1)  # Ensure (batch_size,) shape\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # Save best model\n",
        "    # Check for early stopping\n",
        "    if avg_loss < best_loss:\n",
        "        best_loss = avg_loss\n",
        "        torch.save(model.state_dict(), 'best_model.pth')  # Save best model\n",
        "    else:\n",
        "        print(\"No improvement, applying LR scheduler\")\n",
        "        scheduler.step(avg_loss)  # Reduce learning rate if loss stops improving\n",
        "\n",
        "# -------------------\n",
        "# Evaluation\n",
        "# -------------------\n",
        "model.eval()\n",
        "y_true, y_pred, y_probs = [], [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        inputs, labels = batch\n",
        "        outputs = model(inputs).squeeze(1)\n",
        "        probs = torch.sigmoid(outputs)  # Convert logits to probabilities\n",
        "        predictions = (probs > 0.5).float()  # Threshold at 0.5\n",
        "\n",
        "        y_true.extend(labels.numpy())\n",
        "        y_pred.extend(predictions.numpy())\n",
        "        y_probs.extend(probs.numpy())\n",
        "\n",
        "y_true, y_pred, y_probs = np.array(y_true), np.array(y_pred), np.array(y_probs)\n",
        "\n",
        "# Metrics\n",
        "# Compute evaluation metrics\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "classification_rep = classification_report(y_true, y_pred)\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "roc_auc = roc_auc_score(y_true, y_probs)\n",
        "TN, FP, FN, TP = confusion_matrix(y_true, y_pred).ravel()\n",
        "\n",
        "print('True Positive(TP)  = ', TP)\n",
        "print('False Positive(FP) = ', FP)\n",
        "print('True Negative(TN)  = ', TN)\n",
        "print('False Negative(FN) = ', FN)\n",
        "# Print results\n",
        "print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\n🔹 Classification Report:\\n\", classification_rep)\n",
        "print(\"\\n🔹 Confusion Matrix:\\n\", conf_matrix)\n",
        "print(f\"\\n🔹 ROC-AUC Score: {roc_auc:.4f}\")\n",
        "accuracy =  (TP + TN) / (TP + FP + TN + FN)\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "print(f\"🔹 F1 Score: {f1:.4f}\")\n",
        "print('Accuracy of the binary classifier = {:0.3f}'.format(accuracy))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRnn7OLTC8he",
        "outputId": "d923ee4a-818a-4817-ebb6-3c69032f7e36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-ced868efb01a>:63: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_train, X_test = torch.tensor(X_train, dtype=torch.float32), torch.tensor(X_test, dtype=torch.float32)\n",
            "<ipython-input-29-ced868efb01a>:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  y_train, y_test = torch.tensor(y_train, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.6238\n",
            "Epoch 2, Loss: 0.5751\n",
            "Epoch 3, Loss: 0.5648\n",
            "Epoch 4, Loss: 0.5539\n",
            "Epoch 5, Loss: 0.5474\n",
            "Epoch 6, Loss: 0.5403\n",
            "Epoch 7, Loss: 0.5315\n",
            "Epoch 8, Loss: 0.5292\n",
            "Epoch 9, Loss: 0.5146\n",
            "Epoch 10, Loss: 0.5045\n",
            "Epoch 11, Loss: 0.4975\n",
            "Epoch 12, Loss: 0.4806\n",
            "Epoch 13, Loss: 0.4672\n",
            "Epoch 14, Loss: 0.4736\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 15, Loss: 0.4532\n",
            "Epoch 16, Loss: 0.4400\n",
            "Epoch 17, Loss: 0.4266\n",
            "Epoch 18, Loss: 0.4116\n",
            "Epoch 19, Loss: 0.4055\n",
            "Epoch 20, Loss: 0.3976\n",
            "Epoch 21, Loss: 0.3800\n",
            "Epoch 22, Loss: 0.3688\n",
            "Epoch 23, Loss: 0.3677\n",
            "Epoch 24, Loss: 0.3573\n",
            "Epoch 25, Loss: 0.3396\n",
            "Epoch 26, Loss: 0.3286\n",
            "Epoch 27, Loss: 0.3273\n",
            "Epoch 28, Loss: 0.3411\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 29, Loss: 0.3182\n",
            "Epoch 30, Loss: 0.4557\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 31, Loss: 0.3068\n",
            "Epoch 32, Loss: 0.2986\n",
            "Epoch 33, Loss: 0.2964\n",
            "Epoch 34, Loss: 0.2871\n",
            "Epoch 35, Loss: 0.2901\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 36, Loss: 0.2891\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 37, Loss: 0.2720\n",
            "Epoch 38, Loss: 0.2726\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 39, Loss: 0.2780\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 40, Loss: 0.2660\n",
            "Epoch 41, Loss: 0.2662\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 42, Loss: 0.2548\n",
            "Epoch 43, Loss: 0.2663\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 44, Loss: 0.2598\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 45, Loss: 0.2419\n",
            "Epoch 46, Loss: 0.2477\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 47, Loss: 0.2474\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 48, Loss: 0.2296\n",
            "Epoch 49, Loss: 0.2288\n",
            "Epoch 50, Loss: 0.2363\n",
            "No improvement, applying LR scheduler\n",
            "True Positive(TP)  =  2934\n",
            "False Positive(FP) =  827\n",
            "True Negative(TN)  =  2408\n",
            "False Negative(FN) =  1037\n",
            "✅ Accuracy: 0.7413\n",
            "\n",
            "🔹 Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.70      0.74      0.72      3235\n",
            "         1.0       0.78      0.74      0.76      3971\n",
            "\n",
            "    accuracy                           0.74      7206\n",
            "   macro avg       0.74      0.74      0.74      7206\n",
            "weighted avg       0.74      0.74      0.74      7206\n",
            "\n",
            "\n",
            "🔹 Confusion Matrix:\n",
            " [[2408  827]\n",
            " [1037 2934]]\n",
            "\n",
            "🔹 ROC-AUC Score: 0.8007\n",
            "🔹 F1 Score: 0.7589\n",
            "Accuracy of the binary classifier = 0.741\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, f1_score, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils import resample, compute_class_weight\n",
        "\n",
        "# -------------------\n",
        "# Data Preprocessing\n",
        "# -------------------\n",
        "'''print(eeg_features.shape)\n",
        "print(fmri_features.shape)\n",
        "print(y.shape)\n",
        "\n",
        "# Ensure equal sample sizes\n",
        "num_eeg_samples = eeg_features.shape[0]\n",
        "num_fmri_samples = fmri_features.shape[0]\n",
        "num_samples = max(num_eeg_samples, num_fmri_samples)\n",
        "\n",
        "# Pad or truncate data\n",
        "def pad_or_truncate(data, target_size):\n",
        "    current_size = data.shape[0]\n",
        "    if current_size < target_size:\n",
        "        pad_size = target_size - current_size\n",
        "        pad_shape = (pad_size,) + data.shape[1:]\n",
        "        pad_values = np.zeros(pad_shape)\n",
        "        return np.vstack((data, pad_values))\n",
        "    return data[:target_size]\n",
        "\n",
        "# Apply padding/truncation\n",
        "X_eeg = pad_or_truncate(eeg_features, num_samples)\n",
        "X_fmri = pad_or_truncate(fmri_features, num_samples)\n",
        "y_target = pad_or_truncate(y.reshape(-1, 1), num_samples).flatten()\n",
        "\n",
        "# Reshape fMRI features if necessary\n",
        "X_fmri = X_fmri.reshape(num_samples, -1)\n",
        "\n",
        "# Combine EEG and fMRI features\n",
        "X_combined = np.hstack((X_eeg, X_fmri))\n",
        "\n",
        "# Standardize data\n",
        "ss = StandardScaler()\n",
        "X_combined = ss.fit_transform(X_combined)'''\n",
        "\n",
        "# -------------------\n",
        "# Bootstrapping for Better Generalization\n",
        "# -------------------\n",
        "X_resampled, y_resampled = resample(X_combined, y_target, replace=True, n_samples=num_samples, random_state=42)\n",
        "\n",
        "# -------------------\n",
        "# K-Fold Cross-Validation (Leave 1 Fold for Final Testing)\n",
        "# -------------------\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "splits = list(kf.split(X_resampled, y_resampled))  # Store indices to manually hold 1 fold for final testing\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
        "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "# Store metrics\n",
        "all_accuracies, all_f1_scores, all_roc_auc = [], [], []\n",
        "\n",
        "# Leave the last fold for final testing\n",
        "train_folds = splits[:-1]  # First 4 folds for training\n",
        "test_fold = splits[-1]     # Last fold for testing\n",
        "\n",
        "# Cross-validation on first 4 folds\n",
        "for fold, (train_idx, val_idx) in enumerate(train_folds):\n",
        "    print(f\"\\nTraining fold {fold+1}\")\n",
        "\n",
        "    # Train-test split\n",
        "    X_train, X_val = X_resampled[train_idx], X_resampled[val_idx]\n",
        "    y_train, y_val = y_resampled[train_idx], y_resampled[val_idx]\n",
        "\n",
        "    # Initialize Logistic Regression model\n",
        "    model = LogisticRegression(C=0.01, class_weight='balanced', max_iter=500, solver='lbfgs')\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions\n",
        "    y_pred = model.predict(X_val)\n",
        "    y_probs = model.predict_proba(X_val)[:, 1]\n",
        "\n",
        "    # Compute metrics\n",
        "    accuracy = accuracy_score(y_val, y_pred)\n",
        "    f1 = f1_score(y_val, y_pred)\n",
        "    try:\n",
        "        roc_auc = roc_auc_score(y_val, y_probs)\n",
        "    except ValueError:\n",
        "        roc_auc = None\n",
        "\n",
        "    # Store results\n",
        "    all_accuracies.append(accuracy)\n",
        "    all_f1_scores.append(f1)\n",
        "    if roc_auc is not None:\n",
        "        all_roc_auc.append(roc_auc)\n",
        "\n",
        "    # Print metrics\n",
        "    print(f\"🔹 Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"🔹 F1 Score: {f1:.4f}\")\n",
        "    if roc_auc is not None:\n",
        "        print(f\"🔹 ROC-AUC Score: {roc_auc:.4f}\")\n",
        "    print(\"🔹 Classification Report:\\n\", classification_report(y_val, y_pred))\n",
        "    print(\"🔹 Confusion Matrix:\\n\", confusion_matrix(y_val, y_pred))\n",
        "\n",
        "# -------------------\n",
        "# Compute Average Metrics Across Training Folds\n",
        "# -------------------\n",
        "print(f\"\\n🔹 Average Accuracy: {np.mean(all_accuracies):.4f}\")\n",
        "print(f\"🔹 Average F1 Score: {np.mean(all_f1_scores):.4f}\")\n",
        "if all_roc_auc:\n",
        "    print(f\"🔹 Average ROC-AUC: {np.mean(all_roc_auc):.4f}\")\n",
        "\n",
        "# -------------------\n",
        "# Final Testing on Held-Out Fold\n",
        "# -------------------\n",
        "test_idx = test_fold[1]  # Get test set indices\n",
        "X_test, y_test = X_resampled[test_idx], y_resampled[test_idx]\n",
        "\n",
        "# Predict on test set\n",
        "y_test_pred = model.predict(X_test)\n",
        "y_test_probs = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Compute final test metrics\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "test_f1 = f1_score(y_test, y_test_pred)\n",
        "try:\n",
        "    test_roc_auc = roc_auc_score(y_test, y_test_probs)\n",
        "except ValueError:\n",
        "    test_roc_auc = None\n",
        "\n",
        "# Print final test metrics\n",
        "print(\"\\n🔹 Final Test Results on Held-Out Fold:\")\n",
        "print(f\"🔹 Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"🔹 Test F1 Score: {test_f1:.4f}\")\n",
        "if test_roc_auc is not None:\n",
        "    print(f\"🔹 Test ROC-AUC Score: {test_roc_auc:.4f}\")\n",
        "print(\"🔹 Final Test Classification Report:\\n\", classification_report(y_test, y_test_pred))\n",
        "print(\"🔹 Final Test Confusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5X4TzxTVIva",
        "outputId": "f64b4d43-3a43-4df0-9ff0-38c3e4416700"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training fold 1\n",
            "🔹 Accuracy: 0.7183\n",
            "🔹 F1 Score: 0.6879\n",
            "🔹 ROC-AUC Score: 0.8146\n",
            "🔹 Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.63      0.90      0.74      1302\n",
            "         1.0       0.88      0.57      0.69      1581\n",
            "\n",
            "    accuracy                           0.72      2883\n",
            "   macro avg       0.75      0.73      0.72      2883\n",
            "weighted avg       0.77      0.72      0.71      2883\n",
            "\n",
            "🔹 Confusion Matrix:\n",
            " [[1176  126]\n",
            " [ 686  895]]\n",
            "\n",
            "Training fold 2\n",
            "🔹 Accuracy: 0.7228\n",
            "🔹 F1 Score: 0.6984\n",
            "🔹 ROC-AUC Score: 0.8170\n",
            "🔹 Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.64      0.89      0.74      1301\n",
            "         1.0       0.87      0.59      0.70      1581\n",
            "\n",
            "    accuracy                           0.72      2882\n",
            "   macro avg       0.75      0.74      0.72      2882\n",
            "weighted avg       0.76      0.72      0.72      2882\n",
            "\n",
            "🔹 Confusion Matrix:\n",
            " [[1158  143]\n",
            " [ 656  925]]\n",
            "\n",
            "Training fold 3\n",
            "🔹 Accuracy: 0.7144\n",
            "🔹 F1 Score: 0.6896\n",
            "🔹 ROC-AUC Score: 0.7945\n",
            "🔹 Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.63      0.88      0.74      1301\n",
            "         1.0       0.85      0.58      0.69      1581\n",
            "\n",
            "    accuracy                           0.71      2882\n",
            "   macro avg       0.74      0.73      0.71      2882\n",
            "weighted avg       0.75      0.71      0.71      2882\n",
            "\n",
            "🔹 Confusion Matrix:\n",
            " [[1145  156]\n",
            " [ 667  914]]\n",
            "\n",
            "Training fold 4\n",
            "🔹 Accuracy: 0.7252\n",
            "🔹 F1 Score: 0.6975\n",
            "🔹 ROC-AUC Score: 0.8072\n",
            "🔹 Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.64      0.90      0.75      1301\n",
            "         1.0       0.88      0.58      0.70      1581\n",
            "\n",
            "    accuracy                           0.73      2882\n",
            "   macro avg       0.76      0.74      0.72      2882\n",
            "weighted avg       0.77      0.73      0.72      2882\n",
            "\n",
            "🔹 Confusion Matrix:\n",
            " [[1177  124]\n",
            " [ 668  913]]\n",
            "\n",
            "🔹 Average Accuracy: 0.7202\n",
            "🔹 Average F1 Score: 0.6933\n",
            "🔹 Average ROC-AUC: 0.8083\n",
            "\n",
            "🔹 Final Test Results on Held-Out Fold:\n",
            "🔹 Test Accuracy: 0.7103\n",
            "🔹 Test F1 Score: 0.6817\n",
            "🔹 Test ROC-AUC Score: 0.7981\n",
            "🔹 Final Test Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.63      0.89      0.73      1301\n",
            "         1.0       0.86      0.57      0.68      1581\n",
            "\n",
            "    accuracy                           0.71      2882\n",
            "   macro avg       0.74      0.73      0.71      2882\n",
            "weighted avg       0.75      0.71      0.71      2882\n",
            "\n",
            "🔹 Final Test Confusion Matrix:\n",
            " [[1153  148]\n",
            " [ 687  894]]\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# ... (Your previous code) ...\n",
        "\n",
        "# Ensure all feature vectors are NumPy arrays and have the same length\n",
        "#feature_vectors = [np.array(f) for f in feature_vectors]\n",
        "\n",
        "# Find the maximum feature vector length\n",
        "max_length = max(len(sublist) for f in feature_vectors for sublist in f)  # Modified to find max length across all sublists\n",
        "\n",
        "# Pad all vectors to the same length\n",
        "X = np.array([[np.pad(sublist, (0, max_length - len(sublist)), mode='constant')\n",
        "              for sublist in f] for f in feature_vectors])  # Pad each sublist\n",
        "\n",
        "print(\"Final feature matrix shape:\", X.shape)  # Should be (num_samples, max_length)\n",
        "\n",
        "# ... (Rest of your code) ..."
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgrJ-esf5lmU",
        "outputId": "43d9a962-de03-4af6-e2bf-116970c27024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final feature matrix shape: (6, 50, 2196)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Load features from saved .npy files\n",
        "def load_features(data_dir):\n",
        "    feature_list = []\n",
        "    labels_list = []\n",
        "\n",
        "    # Ensure to use the correct directory variable (output_dir)\n",
        "    for file_name in os.listdir(data_dir):\n",
        "        if file_name.endswith(\"_features.npy\"):  # Make sure we are looking at the correct files\n",
        "            file_path = os.path.join(data_dir, file_name)\n",
        "            try:\n",
        "                features = np.load(file_path)\n",
        "                feature_list.append(features[:, :-1])  # Exclude labels (everything except the last column)\n",
        "                labels_list.append(features[:, -1])   # Labels are the last column (single column)\n",
        "\n",
        "                print(f\"Loaded {file_name}: features shape {features[:, :-1].shape}, labels shape {features[:, -1].shape}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {file_name}: {e}\")\n",
        "\n",
        "    # Concatenate all features and labels from all files\n",
        "    X = np.vstack(feature_list)  # Feature matrix (all rows, all feature columns)\n",
        "    y = np.hstack(labels_list)   # Label vector (all labels)\n",
        "\n",
        "    # Print the shapes of the final feature matrix and label vector\n",
        "    print(f\"Final shape of features matrix (X): {X.shape}\")\n",
        "    print(f\"Final shape of labels vector (y): {y.shape}\")\n",
        "\n",
        "    return X, y\n",
        "\n",
        "\n",
        "# Directory containing EEG feature files\n",
        "output_dir = \"/content/eeg_features/\"\n",
        "eeg_features, y = load_features(output_dir)\n",
        "\n",
        "# Split into training and testing sets\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Assuming X and y are already loaded correctly\n",
        "# X: Features matrix (shape: 14411, 95)\n",
        "# y: Labels vector (shape: 14411,)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(eeg_features, y, test_size=0.25, random_state=0)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "ss = StandardScaler()\n",
        "X_train = ss.fit_transform(X_train)  # Fit & transform on train\n",
        "X_test = ss.transform(X_test)\n",
        "\n",
        "def add_noise(X, noise_level=0.01):\n",
        "    noise = noise_level * np.random.randn(*X.shape)\n",
        "    return X + noise\n",
        "\n",
        "X_train_noisy = add_noise(X_train, noise_level=0.02)\n",
        "X_train_combined = np.vstack((X_train, X_train_noisy))\n",
        "y_train_combined = np.hstack((y_train, y_train))  # Duplicate labels\n",
        "\n",
        "# Convert to tensors again\n",
        "X_train_combined = torch.tensor(X_train_combined, dtype=torch.float32)\n",
        "y_train_combined = torch.tensor(y_train_combined, dtype=torch.long)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# Create DataLoader for batching and shuffling\n",
        "train_data = TensorDataset(X_train_combined, y_train_combined)\n",
        "test_data = TensorDataset(X_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
        "\n",
        "# Define the model\n",
        "class EEGModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(EEGModel, self).__init__()\n",
        "        self.eeg_branch = nn.Sequential(\n",
        "            nn.Linear(input_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),  # Dropout for regularization\n",
        "            nn.Linear(256, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, output_dim)  # Output layer for classification (2 classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.eeg_branch(x)\n",
        "\n",
        "# Initialize the model\n",
        "model = EEGModel(input_dim=eeg_features.shape[1], hidden_dim=256, output_dim=2)  # Adjust hidden_dim as needed\n",
        "\n",
        "# Define loss function and optimizer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
        "\n",
        "# Update the loss function with class weights\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop (use the same code you already have)\n",
        "# Training loop (use the same code you already have)\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "# Add learning rate scheduler\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5, verbose=True)\n",
        "\n",
        "# Modify training loop\n",
        "best_loss = float('inf')\n",
        "for epoch in range(100):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        inputs, labels = batch\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch+1}, Loss: {avg_loss}\")\n",
        "\n",
        "    # Check for early stopping\n",
        "    if avg_loss < best_loss:\n",
        "        best_loss = avg_loss\n",
        "        torch.save(model.state_dict(), 'best_model.pth')  # Save best model\n",
        "    else:\n",
        "        print(\"No improvement, applying LR scheduler\")\n",
        "        scheduler.step(avg_loss)  # Reduce learning rate if loss stops improving\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
        "\n",
        "# Ensure model is in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Store predictions and ground truth labels\n",
        "y_true = []\n",
        "y_pred = []\n",
        "y_probs = []  # For probability scores\n",
        "\n",
        "# Disable gradient computation for evaluation\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        inputs, labels = batch\n",
        "        outputs = model(inputs)  # Get raw logits\n",
        "        probs = torch.softmax(outputs, dim=1)[:, 1]  # Convert to probabilities (class 1)\n",
        "        _, predicted = torch.max(outputs, 1)  # Get class with highest score\n",
        "\n",
        "        y_true.extend(labels.numpy())  # Actual labels\n",
        "        y_pred.extend(predicted.numpy())  # Predicted labels\n",
        "        y_probs.extend(probs.numpy())  # Probability scores\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "y_true = np.array(y_true)\n",
        "y_pred = np.array(y_pred)\n",
        "y_probs = np.array(y_probs)\n",
        "\n",
        "# Compute evaluation metrics\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "classification_rep = classification_report(y_true, y_pred)\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "roc_auc = roc_auc_score(y_true, y_probs)\n",
        "TN, FP, FN, TP = confusion_matrix(y_true, y_pred).ravel()\n",
        "\n",
        "print('True Positive(TP)  = ', TP)\n",
        "print('False Positive(FP) = ', FP)\n",
        "print('True Negative(TN)  = ', TN)\n",
        "print('False Negative(FN) = ', FN)\n",
        "# Print results\n",
        "print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\n🔹 Classification Report:\\n\", classification_rep)\n",
        "print(\"\\n🔹 Confusion Matrix:\\n\", conf_matrix)\n",
        "print(f\"\\n🔹 ROC-AUC Score: {roc_auc:.4f}\")\n",
        "accuracy =  (TP + TN) / (TP + FP + TN + FN)\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "print(f\"🔹 F1 Score: {f1:.4f}\")\n",
        "print('Accuracy of the binary classifier = {:0.3f}'.format(accuracy))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ursYlTkKROAL",
        "outputId": "e765eb00-4ff6-498e-d09f-2ba4434a65a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded h07_features.npy: features shape (454, 95), labels shape (454,)\n",
            "Loaded h12_features.npy: features shape (449, 95), labels shape (449,)\n",
            "Loaded h04_features.npy: features shape (462, 95), labels shape (462,)\n",
            "Loaded h08_features.npy: features shape (454, 95), labels shape (454,)\n",
            "Loaded s05_features.npy: features shape (444, 95), labels shape (444,)\n",
            "Loaded h14_features.npy: features shape (432, 95), labels shape (432,)\n",
            "Loaded s01_features.npy: features shape (422, 95), labels shape (422,)\n",
            "Loaded s07_features.npy: features shape (672, 95), labels shape (672,)\n",
            "Loaded s02_features.npy: features shape (572, 95), labels shape (572,)\n",
            "Loaded h13_features.npy: features shape (482, 95), labels shape (482,)\n",
            "Loaded s04_features.npy: features shape (602, 95), labels shape (602,)\n",
            "Loaded s14_features.npy: features shape (1084, 95), labels shape (1084,)\n",
            "Loaded h03_features.npy: features shape (454, 95), labels shape (454,)\n",
            "Loaded s06_features.npy: features shape (369, 95), labels shape (369,)\n",
            "Loaded s10_features.npy: features shape (424, 95), labels shape (424,)\n",
            "Loaded s03_features.npy: features shape (481, 95), labels shape (481,)\n",
            "Loaded h01_features.npy: features shape (462, 95), labels shape (462,)\n",
            "Loaded h11_features.npy: features shape (457, 95), labels shape (457,)\n",
            "Loaded s08_features.npy: features shape (455, 95), labels shape (455,)\n",
            "Loaded h09_features.npy: features shape (452, 95), labels shape (452,)\n",
            "Loaded s11_features.npy: features shape (679, 95), labels shape (679,)\n",
            "Loaded h02_features.npy: features shape (454, 95), labels shape (454,)\n",
            "Loaded h10_features.npy: features shape (557, 95), labels shape (557,)\n",
            "Loaded s12_features.npy: features shape (543, 95), labels shape (543,)\n",
            "Loaded h06_features.npy: features shape (464, 95), labels shape (464,)\n",
            "Loaded s13_features.npy: features shape (567, 95), labels shape (567,)\n",
            "Loaded h05_features.npy: features shape (472, 95), labels shape (472,)\n",
            "Loaded s09_features.npy: features shape (592, 95), labels shape (592,)\n",
            "Final shape of features matrix (X): (14411, 95)\n",
            "Final shape of labels vector (y): (14411,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.6427615161478166\n",
            "Epoch 2, Loss: 0.5587898084574198\n",
            "Epoch 3, Loss: 0.5212043492046333\n",
            "Epoch 4, Loss: 0.507072869930747\n",
            "Epoch 5, Loss: 0.49530911357445123\n",
            "Epoch 6, Loss: 0.4885310642641677\n",
            "Epoch 7, Loss: 0.47668136003807454\n",
            "Epoch 8, Loss: 0.4694664723421695\n",
            "Epoch 9, Loss: 0.6478887118355057\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 10, Loss: 0.45457844356813376\n",
            "Epoch 11, Loss: 0.46505295569022026\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 12, Loss: 0.44103509469850527\n",
            "Epoch 13, Loss: 0.43192120116843274\n",
            "Epoch 14, Loss: 0.4404962235653894\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 15, Loss: 0.41914738886631453\n",
            "Epoch 16, Loss: 0.4100108416475488\n",
            "Epoch 17, Loss: 0.40240588546151945\n",
            "Epoch 18, Loss: 0.39765056870745485\n",
            "Epoch 19, Loss: 0.3914744392390082\n",
            "Epoch 20, Loss: 0.38608605467532514\n",
            "Epoch 21, Loss: 0.37885227534897936\n",
            "Epoch 22, Loss: 0.4210988597933357\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 23, Loss: 0.37167627249772733\n",
            "Epoch 24, Loss: 0.37760312665672696\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 25, Loss: 0.36319677774193726\n",
            "Epoch 26, Loss: 0.3669567161057828\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 27, Loss: 0.360164750521705\n",
            "Epoch 28, Loss: 0.3541039983637234\n",
            "Epoch 29, Loss: 0.34987103326257163\n",
            "Epoch 30, Loss: 0.3474104753171904\n",
            "Epoch 31, Loss: 0.3418479447622271\n",
            "Epoch 32, Loss: 0.34304113584686313\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 33, Loss: 0.34022728058360735\n",
            "Epoch 34, Loss: 0.34240427190030115\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 35, Loss: 0.3311209869543476\n",
            "Epoch 36, Loss: 0.3303583937989184\n",
            "Epoch 37, Loss: 0.33681563614211846\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 38, Loss: 0.3242086677773464\n",
            "Epoch 39, Loss: 0.3215440114486147\n",
            "Epoch 40, Loss: 0.32142200713326946\n",
            "Epoch 41, Loss: 0.31446244135587176\n",
            "Epoch 42, Loss: 0.30943358654277564\n",
            "Epoch 43, Loss: 0.30287820960466677\n",
            "Epoch 44, Loss: 0.3066254983815921\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 45, Loss: 0.3015003271797705\n",
            "Epoch 46, Loss: 0.2978044954189182\n",
            "Epoch 47, Loss: 0.29266548500611234\n",
            "Epoch 48, Loss: 0.29295584634387284\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 49, Loss: 0.2849281901306302\n",
            "Epoch 50, Loss: 0.28779363111984096\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 51, Loss: 0.2840268165313986\n",
            "Epoch 52, Loss: 0.291989397191437\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 53, Loss: 0.2790983176002136\n",
            "Epoch 54, Loss: 0.27653252688297153\n",
            "Epoch 55, Loss: 0.27136286224662903\n",
            "Epoch 56, Loss: 0.2641640195082983\n",
            "Epoch 57, Loss: 0.26480263125526127\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 58, Loss: 0.2617722453891173\n",
            "Epoch 59, Loss: 0.28714808645333056\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 60, Loss: 0.26559479422206006\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 61, Loss: 0.25993237523196716\n",
            "Epoch 62, Loss: 0.25877423039995706\n",
            "Epoch 63, Loss: 0.25675355953842227\n",
            "Epoch 64, Loss: 0.3021878757508549\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 65, Loss: 0.2771681878473279\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 66, Loss: 0.23419860470488932\n",
            "Epoch 67, Loss: 0.22362633106800225\n",
            "Epoch 68, Loss: 0.22852825186044506\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 69, Loss: 0.222099300562101\n",
            "Epoch 70, Loss: 0.22255667583388689\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 71, Loss: 0.221702363386133\n",
            "Epoch 72, Loss: 0.22010553868476457\n",
            "Epoch 73, Loss: 0.21366814892055722\n",
            "Epoch 74, Loss: 0.21494699675126894\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 75, Loss: 0.2172498732320303\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 76, Loss: 0.21661091501102644\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 77, Loss: 0.20883601105953814\n",
            "Epoch 78, Loss: 0.20914057421790072\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 79, Loss: 0.22380109975588391\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 80, Loss: 0.20232443363797029\n",
            "Epoch 81, Loss: 0.20313667459688947\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 82, Loss: 0.2058648438628256\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 83, Loss: 0.20365894394072556\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 84, Loss: 0.20387678485385766\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 85, Loss: 0.21271788586790746\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 86, Loss: 0.1916051027337475\n",
            "Epoch 87, Loss: 0.1885382211023181\n",
            "Epoch 88, Loss: 0.19613105168885733\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 89, Loss: 0.1857503064020851\n",
            "Epoch 90, Loss: 0.18413889807092368\n",
            "Epoch 91, Loss: 0.19167190144312451\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 92, Loss: 0.18601582126592744\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 93, Loss: 0.17877605927766427\n",
            "Epoch 94, Loss: 0.18478100299394343\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 95, Loss: 0.1867592320419275\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 96, Loss: 0.1824070846871335\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 97, Loss: 0.17928743151914792\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 98, Loss: 0.18339371482825137\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 99, Loss: 0.18202845852535504\n",
            "No improvement, applying LR scheduler\n",
            "Epoch 100, Loss: 0.17923119822902792\n",
            "No improvement, applying LR scheduler\n",
            "True Positive(TP)  =  1805\n",
            "False Positive(FP) =  71\n",
            "True Negative(TN)  =  1563\n",
            "False Negative(FN) =  164\n",
            "✅ Accuracy: 0.9348\n",
            "\n",
            "🔹 Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.96      0.93      1634\n",
            "           1       0.96      0.92      0.94      1969\n",
            "\n",
            "    accuracy                           0.93      3603\n",
            "   macro avg       0.93      0.94      0.93      3603\n",
            "weighted avg       0.94      0.93      0.93      3603\n",
            "\n",
            "\n",
            "🔹 Confusion Matrix:\n",
            " [[1563   71]\n",
            " [ 164 1805]]\n",
            "\n",
            "🔹 ROC-AUC Score: 0.9817\n",
            "🔹 F1 Score: 0.9389\n",
            "Accuracy of the binary classifier = 0.935\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "\n",
        "# Define Autoencoder class\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, input_dim, latent_dim):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, latent_dim)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, input_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return encoded, decoded\n",
        "\n",
        "# Initialize Autoencoder\n",
        "print(X.shape, X.shape[0], X.shape[1])\n",
        "input_dim = X.shape[2]  # Ensure correct shape after padding\n",
        "latent_dim = 32\n",
        "autoencoder = Autoencoder(input_dim, latent_dim)\n",
        "\n",
        "# Set up optimizer and loss function\n",
        "optimizer = optim.Adam(autoencoder.parameters(), lr=1e-3)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Convert X to a PyTorch tensor\n",
        "X_tensor = torch.FloatTensor(X)\n",
        "\n",
        "# Train Autoencoder\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    autoencoder.train()\n",
        "    optimizer.zero_grad()\n",
        "    encoded, decoded = autoencoder(X_tensor)\n",
        "    loss = criterion(decoded, X_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Extract latent features\n",
        "autoencoder.eval()\n",
        "with torch.no_grad():\n",
        "    fmri_features_old, _ = autoencoder(X_tensor)\n",
        "\n",
        "# Convert features to NumPy for clustering\n",
        "fmri_features_np = fmri_features_old.numpy()\n",
        "print('dim', fmri_features_np.shape)\n",
        "# Apply K-Means Clustering\n",
        "n_clusters = 2  # Choose the number of clusters\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "# Reshape to ensure it's (num_samples, latent_dim)\n",
        "fmri_features_np = fmri_features_np.reshape(fmri_features_np.shape[0], -1)\n",
        "cluster_labels = kmeans.fit_predict(fmri_features_np)\n",
        "\n",
        "print(\"Cluster Labels:\", cluster_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2quj0tnv51tg",
        "outputId": "8b06a3d9-a1be-41c8-d685-2e878e29ce1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6, 50, 2196) 6 50\n",
            "Epoch [10/100], Loss: 0.1345\n",
            "Epoch [20/100], Loss: 0.0570\n",
            "Epoch [30/100], Loss: 0.0385\n",
            "Epoch [40/100], Loss: 0.0263\n",
            "Epoch [50/100], Loss: 0.0201\n",
            "Epoch [60/100], Loss: 0.0168\n",
            "Epoch [70/100], Loss: 0.0147\n",
            "Epoch [80/100], Loss: 0.0130\n",
            "Epoch [90/100], Loss: 0.0116\n",
            "Epoch [100/100], Loss: 0.0104\n",
            "dim (6, 50, 32)\n",
            "Cluster Labels: [0 0 0 0 1 0]\n"
          ]
        }
      ]
    }
  ]
}